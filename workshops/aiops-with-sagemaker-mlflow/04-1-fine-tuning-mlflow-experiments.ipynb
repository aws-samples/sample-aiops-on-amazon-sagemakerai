{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f946b5",
   "metadata": {},
   "source": [
    "## Fine-tuning LLMs and Experiment Tracking with MLflow üß™\n",
    "\n",
    "Most of our MLflow configurations exist in our training script `sft.py`. This is where we import the MLflow library, set our tracking server, name our experiments and runs and log artifiacts, parameters, and metrics. MLflow has direct integration with Huggingface Transformers library to make it easy to setup. \n",
    "\n",
    "## Setting Up MLflow\n",
    "\n",
    "Getting started with MLflow is straightforward. You can install MLflow using pip:\n",
    "\n",
    "```bash\n",
    "pip install mlflow\n",
    "pip install mlflow-sagemaker\n",
    "```\n",
    "\n",
    "The second package is needed to set a tracking server in SageMaker with an Amazon Resource Name (ARN). Once these two packages are installed you import the mlflow library and set the tracking URI to your SageMaker tracking server and name your experiment.\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"your_sagemaker_tracking_uri\")\n",
    "mlflow.set_experiment(\"your_experiment_name\")\n",
    "```\n",
    "\n",
    "Next you need to start a run. A run can be a fine-tuning job or an evaluation job. Runs can be nested with a parent child relationship to remember which jobs are related to each other. Once you have initiated a run you can log different items to MLflow. \n",
    "\n",
    "```python\n",
    "with mlflow.start_run(run_name='training-job-1') as run:\n",
    "    trainer.train()\n",
    "    mlflow.log_metrics('loss': 0.05)\n",
    "    mlflow.log_param(\"learning_rate\", 0.01)\n",
    "    mlflow.log_artifact('recipe.yaml')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce40054-610a-4acc-a546-943893f293c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %uv pip install -Uq sagemaker datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b791e72e-82b5-4f8e-a7fe-700e8afdeba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# from PIL import Image\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c673a9-5b9f-47e0-92cf-bb97486b3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "\n",
    "# from sagemaker.local import LocalSession\n",
    "# sess = LocalSession() #sagemaker.Session(boto3.Session(region_name=region))\n",
    "# sess.config = {\"local\": {\"local_code\": True}}\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9786901-b012-41ff-a98a-b16e5f60ec9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::198346569064:role/service-role/AmazonSageMaker-ExecutionRole-20250915T164900\n",
      "sagemaker bucket: sagemaker-us-east-1-198346569064\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145954cd",
   "metadata": {},
   "source": [
    "## Data Preparation for Supervised Fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bdc257",
   "metadata": {},
   "source": [
    "### [Finance-Instruct-500k](https://huggingface.co/datasets/Josephgflowers/Finance-Instruct-500k)\n",
    "\n",
    "**Finance-Instruct-500k** is a large-scale dataset with about **518,000 entries** focused on the financial domain. It spans topics such as investments, banking, markets, accounting, and corporate finance, offering a wide variety of instruction‚Äìresponse examples.\n",
    "\n",
    "**Data Format & Structure**:\n",
    "\n",
    "- Distributed in **JSON** format, with simple conversion to Parquet.\n",
    "- Contains a single `train` split with ~518k records.\n",
    "- Each record includes:\n",
    "  - `system` ‚Äì context or metadata for the task\n",
    "  - `user` ‚Äì the financial prompt or query\n",
    "  - `assistant` ‚Äì the corresponding response\n",
    "\n",
    "**License**: Released under the **Apache-2.0** license.\n",
    "\n",
    "**Applications**:\n",
    "\n",
    "The dataset can support finance-focused tasks such as:\n",
    "\n",
    "- Financial question answering\n",
    "- Market and investment analysis\n",
    "- Topic and sentiment classification\n",
    "- Financial entity extraction and document understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc26be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed7366",
   "metadata": {},
   "source": [
    "**Preparing Your Dataset in `messages` format**\n",
    "\n",
    "This section walks you through creating a conversation-style dataset‚Äîthe required `messages` format‚Äîfor directly training LLMs using SageMaker AI.\n",
    "\n",
    "**What Is the `messages` Format?**\n",
    "\n",
    "The `messages` format structures instances as chat-like exchanges, wrapping each conversation turn into a role-labeled JSON array. It‚Äôs widely used by frameworks like TRL.\n",
    "\n",
    "Example entry:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "    { \"role\": \"user\", \"content\": \"How do I bake sourdough?\" },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"First, you need to create a starter by...\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3921310",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Josephgflowers/Finance-Instruct-500k\"\n",
    "dataset = load_dataset(\n",
    "    dataset_name, split=\"train[:100]\"\n",
    ")  # just a toy example with 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ee8fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system': '\\n',\n",
      " 'user': 'Explain tradeoffs between fiscal and monetary policy as tools in a '\n",
      "         \"nation's economic toolkit. Provide examples of past instances when \"\n",
      "         'each were utilized, the economic conditions that led to them being '\n",
      "         'deployed, their intended effects, and an evaluation of their '\n",
      "         'relative efficacy and consequences.',\n",
      " 'assistant': 'Fiscal and monetary policy are the two main tools that '\n",
      "              'governments have to influence economic activity. They each have '\n",
      "              'benefits and drawbacks.\\n'\n",
      "              '\\n'\n",
      "              'Fiscal policy refers to government spending and taxation '\n",
      "              'decisions. Examples of fiscal policy include:\\n'\n",
      "              '\\n'\n",
      "              '‚Ä¢ During the Great Recession, the U.S. government implemented a '\n",
      "              'fiscal stimulus through the American Recovery and Reinvestment '\n",
      "              'Act of 2009. This included increased spending on '\n",
      "              'infrastructure, tax cuts, and expanded unemployment benefits. '\n",
      "              'The intention was to boost aggregate demand and stimulate '\n",
      "              'economic activity. Studies have found that the stimulus had a '\n",
      "              'positive but modest impact on economic growth.\\n'\n",
      "              '\\n'\n",
      "              '‚Ä¢ The Trump administration implemented tax cuts in 2017 with '\n",
      "              'the goal of increasing business investment and growth. However, '\n",
      "              'the effect on growth has been debated, and the tax cuts '\n",
      "              'significantly increased the federal budget deficit.\\n'\n",
      "              '\\n'\n",
      "              'Monetary policy refers to decisions by a central bank, like the '\n",
      "              'Federal Reserve, about interest rates and the money supply. '\n",
      "              'Examples of monetary policy include:\\n'\n",
      "              '\\n'\n",
      "              '‚Ä¢ After the 2008 financial crisis, the Fed lowered interest '\n",
      "              'rates to near zero and implemented quantitative easing programs '\n",
      "              'to increase liquidity. The intention was to boost lending, '\n",
      "              'investment, and consumer spending. These actions are credited '\n",
      "              'with helping the economy recover.\\n'\n",
      "              '\\n'\n",
      "              '‚Ä¢ In the late 1990s, the Fed raised interest rates to reduce '\n",
      "              'inflationary pressures from economic growth. Higher rates '\n",
      "              'contributed to slowing the economy and avoiding a spike in '\n",
      "              'prices.\\n'\n",
      "              '\\n'\n",
      "              'The key tradeoffs are:\\n'\n",
      "              '\\n'\n",
      "              '‚Ä¢ Fiscal policy can have a more targeted impact but takes '\n",
      "              'longer to implement due to the political process. Monetary '\n",
      "              'policy is more nimble but has a broader influence on the '\n",
      "              'economy.\\n'\n",
      "              '\\n'\n",
      "              '‚Ä¢ Fiscal policy impacts the budget deficit, while monetary '\n",
      "              'policy does not directly affect government debt. However, very '\n",
      "              'low interest rates due to monetary policy can encourage higher '\n",
      "              'government borrowing. \\n'\n",
      "              '\\n'\n",
      "              '‚Ä¢ Monetary policy tends to be less politically contentious, '\n",
      "              'while fiscal policy proposals often face more opposition.\\n'\n",
      "              '\\n'\n",
      "              'In summary, both tools have pros and cons and work best in '\n",
      "              'tandem to stabilize the economy and maximize growth. The '\n",
      "              'optimal mix depends on the specific economic conditions and '\n",
      "              'policy goals.'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "773ec6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of fine-tunable samples: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"total number of fine-tunable samples: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "025f7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_messages(row):\n",
    "    system_content = \"You are a financial reasoning assistant. Read the user‚Äôs query, restate the key data, and solve step by step. Show calculations clearly, explain any rounding or adjustments, and present the final answer in a concise and professional manner.\"\n",
    "    user_content = row[\"user\"]\n",
    "    assistant_content = row[\"assistant\"]\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_content},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "dataset = dataset.map(convert_to_messages, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b8887de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_parent_path = os.path.join(os.getcwd(), \"data\")\n",
    "os.makedirs(dataset_parent_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0434ac7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b99312bd016485286a5375c308a27f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "219569"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_filename = os.path.join(\n",
    "    dataset_parent_path,\n",
    "    \"finance-instruct-500k.jsonl\",\n",
    ")\n",
    "dataset.to_json(dataset_filename, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b376313e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sagemaker-user/aiops-fine-tune-eval/data/finance-instruct-500k.jsonl'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8bf70",
   "metadata": {},
   "source": [
    "#### Upload file to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abb9962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c9686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "819d2e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded /home/sagemaker-user/aiops-fine-tune-eval/data/finance-instruct-500k.jsonl to:\n",
      "s3://sagemaker-us-east-1-198346569064/dataset/finance-instruct-500k.jsonl\n"
     ]
    }
   ],
   "source": [
    "data_s3_uri = f\"s3://{sess.default_bucket()}/dataset\"\n",
    "\n",
    "uploaded_s3_uri = S3Uploader.upload(\n",
    "    local_path=dataset_filename, desired_s3_uri=data_s3_uri\n",
    ")\n",
    "print(f\"Uploaded {dataset_filename} to:\")\n",
    "print(uploaded_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb0000",
   "metadata": {},
   "source": [
    "## Fine-Tune LLMs using SageMaker `Estimator`/`ModelTrainer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f80210ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from getpass import getpass\n",
    "import yaml\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc62cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d2e06",
   "metadata": {},
   "source": [
    "### Training using `PyTorch` Estimator\n",
    "\n",
    "**Training Using `PyTorch` Estimator**\n",
    "Leverages the official PyTorch SageMaker container to run a custom training script using the Accelerate and DeepSpeed libraries. This option is ideal for users who want full control over the training pipeline\n",
    "\n",
    "---\n",
    "\n",
    "**Observability**: SageMaker AI has [SageMaker MLflow](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html) which enables you to accelerate generative AI by making it easier to track experiments and monitor performance of models and AI applications using a single tool.\n",
    "\n",
    "You can choose to include MLflow as a part of your training workflow to track your model fine-tuning metrics in realtime by simply specifying a **mlflow** tracking arn.\n",
    "\n",
    "Optionally you can also report to : **tensorboard**, **wandb**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd327996",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_SERVER_ARN = 'arn:aws:sagemaker:us-east-1:198346569064:mlflow-tracking-server/vlm-finetuning-server'  # or \"arn:aws:sagemaker:us-west-2:<account-id>:mlflow-tracking-server/<server-name>\"\n",
    "\n",
    "if MLFLOW_TRACKING_SERVER_ARN:\n",
    "    reports_to = \"mlflow\"\n",
    "else:\n",
    "    reports_to = \"tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6ff69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 'qwen3-06b-lora-ft-finance'  # cannot use '.' in name\n",
    "instance_type = \"ml.g5.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d1f65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MLFLOW_TRACKING_SERVER_ARN:\n",
    "    environment = {\n",
    "        \"MLFLOW_EXPERIMENT_NAME\": job_name,\n",
    "        \"MLFLOW_TAGS\": '{\"source.job\": \"sm-training-jobs\", \"source.type\": \"sft\", \"source.framework\": \"pytorch\"}',\n",
    "        \"HF_TOKEN\": hf_token,\n",
    "        \"MLFLOW_TRACKING_URI\": MLFLOW_TRACKING_SERVER_ARN,\n",
    "    }\n",
    "else:\n",
    "    environment = {\"HF_TOKEN\": hf_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c7868fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using image: 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.8.0-gpu-py312-cu129-ubuntu22.04-sagemaker\n"
     ]
    }
   ],
   "source": [
    "pytorch_image_uri = f\"763104351884.dkr.ecr.{region}.amazonaws.com/pytorch-training:2.8.0-gpu-py312-cu129-ubuntu22.04-sagemaker\"\n",
    "print(f\"Using image: {pytorch_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cdb9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_run_description = '''\n",
    "    AIops MLflow Workshop\n",
    "\n",
    "    This section shows how to fine-tune a model and track experiments with MLflow tracking UI server. \n",
    "    Once models are fine-tuned they can be evaluated using MLflow built in metrics and LLM-as-a-judge\n",
    "    functionality. \n",
    "\n",
    "    The fine-tuned model is Qwen3 0.6B and fine-tuned on a finance reasoning dataset.\n",
    "    '''\n",
    "\n",
    "hyperparameters = {\n",
    "    \"config\": \"qwen3-0.6b.yaml\",\n",
    "    \"mlflow_run_description\": mlflow_run_description,\n",
    "    # \"mlflow_experiment_name\": job_name,\n",
    "    # \"mlflow_tags\": '{\"source.job\": \"sm-training-jobs\", \"source.type\": \"sft\", \"source.framework\": \"pytorch\"}',\n",
    "    # \"hf_token\": hf_token,\n",
    "    # \"mlflow_tracking_server\": MLFLOW_TRACKING_SERVER_ARN,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe43f9a",
   "metadata": {},
   "source": [
    "#### Training strategy: `PeFT/LoRA`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a32ecd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: qwen3-06b-lora-ft-finance-2025-10-09-15-08-59-366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-09 15:09:00 Starting - Starting the training job\n",
      "2025-10-09 15:09:00 Pending - Training job waiting for capacity...\n",
      "2025-10-09 15:09:34 Pending - Preparing the instances for training......\n",
      "2025-10-09 15:10:16 Downloading - Downloading the training image..............................\n",
      "2025-10-09 15:15:09 Training - Training image download completed. Training in progress...bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "CUDA compat package should be installed for NVIDIA driver smaller than 575.57.08\n",
      "Current installed NVIDIA driver version is 570.172.08\n",
      "Adding CUDA compat to LD_LIBRARY_PATH\n",
      "/usr/local/cuda/compat:/usr/local/cuda/compat:/usr/local/lib:/opt/amazon/ofi-nccl/lib/x86_64-linux-gnu:/opt/amazon/openmpi/lib:/opt/amazon/efa/lib:/usr/local/cuda/lib64:/usr/local/lib:/usr/local/cuda/lib64:/opt/amazon/ofi-nccl/lib:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/lib64\n",
      "2025-10-09 15:15:48,027 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2025-10-09 15:15:48,047 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-10-09 15:15:48,058 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2025-10-09 15:15:48,060 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2025-10-09 15:15:49,276 sagemaker-training-toolkit INFO     Provided path: /opt/ml/code  is empty, unzipping\n",
      "2025-10-09 15:15:49,656 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-10-09 15:15:49,750 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-10-09 15:15:49,780 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2025-10-09 15:15:49,791 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config\": \"qwen3-0.6b.yaml\",\n",
      "        \"mlflow_run_description\": \"\\n    AIops MLflow Workshop\\n\\n    This section shows how to fine-tune a model and track experiments with MLflow tracking UI server. \\n    Once models are fine-tuned they can be evaluated using MLflow built in metrics and LLM-as-a-judge\\n    functionality. \\n\\n    The fine-tuned model is Qwen3 0.6B and fine-tuned on a finance reasoning dataset.\\n    \"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"qwen3-06b-lora-ft-finance-2025-10-09-15-08-59-366\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-198346569064/qwen3-06b-lora-ft-finance-2025-10-09-15-08-59-366/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"topology\": null,\n",
      "    \"user_entry_point\": \"train.sh\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"config\":\"qwen3-0.6b.yaml\",\"mlflow_run_description\":\"\\n    AIops MLflow Workshop\\n\\n    This section shows how to fine-tune a model and track experiments with MLflow tracking UI server. \\n    Once models are fine-tuned they can be evaluated using MLflow built in metrics and LLM-as-a-judge\\n    functionality. \\n\\n    The fine-tuned model is Qwen3 0.6B and fine-tuned on a finance reasoning dataset.\\n    \"}\n",
      "SM_USER_ENTRY_POINT=train.sh\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\n",
      "SM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=train.sh\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=1\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-198346569064/qwen3-06b-lora-ft-finance-2025-10-09-15-08-59-366/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config\":\"qwen3-0.6b.yaml\",\"mlflow_run_description\":\"\\n    AIops MLflow Workshop\\n\\n    This section shows how to fine-tune a model and track experiments with MLflow tracking UI server. \\n    Once models are fine-tuned they can be evaluated using MLflow built in metrics and LLM-as-a-judge\\n    functionality. \\n\\n    The fine-tuned model is Qwen3 0.6B and fine-tuned on a finance reasoning dataset.\\n    \"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"qwen3-06b-lora-ft-finance-2025-10-09-15-08-59-366\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-198346569064/qwen3-06b-lora-ft-finance-2025-10-09-15-08-59-366/source/sourcedir.tar.gz\",\"module_name\":\"train.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"topology\":null,\"user_entry_point\":\"train.sh\"}\n",
      "SM_USER_ARGS=[\"--config\",\"qwen3-0.6b.yaml\",\"--mlflow_run_description\",\"\\n    AIops MLflow Workshop\\n\\n    This section shows how to fine-tune a model and track experiments with MLflow tracking UI server. \\n    Once models are fine-tuned they can be evaluated using MLflow built in metrics and LLM-as-a-judge\\n    functionality. \\n\\n    The fine-tuned model is Qwen3 0.6B and fine-tuned on a finance reasoning dataset.\\n    \"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_CONFIG=qwen3-0.6b.yaml\n",
      "SM_HP_MLFLOW_RUN_DESCRIPTION=\n",
      "    AIops MLflow Workshop\n",
      "    This section shows how to fine-tune a model and track experiments with MLflow tracking UI server. \n",
      "    Once models are fine-tuned they can be evaluated using MLflow built in metrics and LLM-as-a-judge\n",
      "    functionality. \n",
      "    The fine-tuned model is Qwen3 0.6B and fine-tuned on a finance reasoning dataset.\n",
      "    \n",
      "PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python312.zip:/usr/local/lib/python3.12:/usr/local/lib/python3.12/lib-dynload:/usr/local/lib/python3.12/site-packages\n",
      "Invoking script with the following command:\n",
      "/bin/sh -c \"./train.sh --config qwen3-0.6b.yaml --mlflow_run_description '\n",
      "    AIops MLflow Workshop\n",
      "    This section shows how to fine-tune a model and track experiments with MLflow tracking UI server. \n",
      "    Once models are fine-tuned they can be evaluated using MLflow built in metrics and LLM-as-a-judge\n",
      "    functionality. \n",
      "    The fine-tuned model is Qwen3 0.6B and fine-tuned on a finance reasoning dataset.\n",
      "    '\"\n",
      "2025-10-09 15:15:49,792 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "2025-10-09 15:15:49,792 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Collecting uv\n",
      "Downloading uv-0.9.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Downloading uv-0.9.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.2 MB)\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21.2/21.2 MB 167.6 MB/s  0:00:00\n",
      "Installing collected packages: uv\n",
      "Successfully installed uv-0.9.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "Using Python 3.12.10 environment at: /usr/local\n",
      "Updating https://github.com/triton-lang/triton.git (main)\n",
      "Updated https://github.com/triton-lang/triton.git (3419eedd7749f59a28af65466561623d400d3212)\n",
      "Resolved 311 packages in 5.65s\n",
      "Downloading nvidia-cusparse-cu12 (206.5MiB)\n",
      "Downloading mlflow (25.5MiB)\n",
      "Downloading zstandard (5.3MiB)\n",
      "Downloading lxml (5.0MiB)\n",
      "Downloading rapidfuzz (3.0MiB)\n",
      "Downloading tokenizers (3.0MiB)\n",
      "Downloading pycryptodomex (2.2MiB)\n",
      "Downloading mlflow-skinny (2.1MiB)\n",
      "Downloading aiohttp (1.7MiB)\n",
      "Downloading nltk (1.4MiB)\n",
      "Downloading nvidia-cuda-nvrtc-cu12 (22.6MiB)\n",
      "Building triton-kernels @ git+https://github.com/triton-lang/triton.git@3419eedd7749f59a28af65466561623d400d3212#subdirectory=python/triton_kernels\n",
      "Downloading pycountry (6.0MiB)\n",
      "Downloading outlines-core (2.2MiB)\n",
      "Downloading virtualenv (5.7MiB)\n",
      "Downloading sqlalchemy (3.2MiB)\n",
      "Downloading opencv-python-headless (47.7MiB)\n",
      "Downloading brotli (2.8MiB)\n",
      "Downloading llguidance (14.3MiB)\n",
      "Downloading xgrammar (11.3MiB)\n",
      "Downloading torchvision (7.1MiB)\n",
      "Downloading xformers (111.6MiB)\n",
      "Downloading cryptography (4.3MiB)\n",
      "Downloading cupy-cuda12x (107.7MiB)\n",
      "Downloading numba (3.7MiB)\n",
      "Downloading torch (783.0MiB)\n",
      "Downloading transformers (10.7MiB)\n",
      "Downloading vllm (395.2MiB)\n",
      "Downloading setuptools (1.2MiB)\n",
      "Downloading torchaudio (3.3MiB)\n",
      "Downloading lm-eval (7.1MiB)\n",
      "Downloading nvidia-cusolver-cu12 (150.9MiB)\n",
      "Downloading bitsandbytes (69.5MiB)\n",
      "Downloading triton (148.5MiB)\n",
      "Downloading nvidia-nccl-cu12 (192.0MiB)\n",
      "Downloading uvloop (4.5MiB)\n",
      "Downloading nvidia-cusparselt-cu12 (149.5MiB)\n",
      "Downloading nvidia-cufft-cu12 (190.9MiB)\n",
      "Downloading soundfile (1.3MiB)\n",
      "Downloading ray (66.9MiB)\n",
      "Downloading nvidia-nvjitlink-cu12 (18.8MiB)\n",
      "Downloading nvidia-cuda-cupti-cu12 (8.5MiB)\n",
      "Downloading hf-transfer (3.4MiB)\n",
      "Downloading nvidia-cublas-cu12 (374.9MiB)\n",
      "Downloading llvmlite (40.4MiB)\n",
      "Downloading sentencepiece (1.2MiB)\n",
      "Downloading nvidia-curand-cu12 (53.7MiB)\n",
      "Downloading nvidia-cudnn-cu12 (544.5MiB)\n",
      "Downloading openai-harmony (2.9MiB)\n",
      "Downloading mistral-common (6.2MiB)\n",
      "Downloading sagemaker (1.6MiB)\n",
      "Downloading soundfile\n",
      "Downloading dulwich (1.2MiB)\n",
      "Downloading sentencepiece\n",
      "Downloading mlflow-tracing (1.2MiB)\n",
      "Built triton-kernels @ git+https://github.com/triton-lang/triton.git@3419eedd7749f59a28af65466561623d400d3212#subdirectory=python/triton_kernels\n",
      "Downloading aiohttp\n",
      "Downloading tiktoken (1.1MiB)\n",
      "Downloading nltk\n",
      "Downloading nvidia-cufile-cu12 (1.1MiB)\n",
      "Downloading setuptools\n",
      "Downloading outlines-core\n",
      "Downloading pycryptodomex\n",
      "Downloading sagemaker\n",
      "Downloading brotli\n",
      "Downloading dulwich\n",
      "Downloading tiktoken\n",
      "Downloading nvidia-cufile-cu12\n",
      "Downloading tokenizers\n",
      "Downloading rapidfuzz\n",
      "Downloading openai-harmony\n",
      "Downloading sqlalchemy\n",
      "Downloading mlflow-tracing\n",
      "Downloading torchaudio\n",
      "Downloading hf-transfer\n",
      "Downloading mlflow-skinny\n",
      "Downloading numba\n",
      "Downloading cryptography\n",
      "Downloading uvloop\n",
      "Downloading zstandard\n",
      "Downloading virtualenv\n",
      "Downloading lxml\n",
      "Downloading pycountry\n",
      "Building deepspeed==0.17.5\n",
      "Building sqlitedict==2.1.0\n",
      "Building word2number==1.1\n",
      "Building rouge-score==0.1.2\n",
      "Downloading mistral-common\n",
      "Downloading torchvision\n",
      "Built sqlitedict==2.1.0\n",
      "Built rouge-score==0.1.2\n",
      "Built word2number==1.1\n",
      "Downloading nvidia-cuda-cupti-cu12\n",
      "Downloading\n",
      "xgrammar\n",
      "Downloading transformers\n",
      "Downloading llguidance\n",
      "Downloading nvidia-nvjitlink-cu12\n",
      "Downloading nvidia-cuda-nvrtc-cu12\n",
      "Downloading mlflow\n",
      "Downloading llvmlite\n",
      "Downloading opencv-python-headless\n",
      "Built deepspeed==0.17.5\n",
      "Downloading nvidia-curand-cu12\n",
      "Downloading bitsandbytes\n",
      "Downloading ray\n",
      "Downloading cupy-cuda12x\n",
      "Downloading xformers\n",
      "Downloading nvidia-cusparselt-cu12\n",
      "Downloading nvidia-cusolver-cu12\n",
      "Downloading triton\n",
      "Downloading nvidia-nccl-cu12\n",
      "Downloading nvidia-cufft-cu12\n",
      "Downloading nvidia-cusparse-cu12\n",
      "Downloading nvidia-cublas-cu12\n",
      "Downloading vllm\n",
      "Downloading nvidia-cudnn-cu12\n",
      "Downloading lm-eval\n",
      "Downloading torch\n",
      "Prepared 213 packages in 33.19s\n",
      "Uninstalled 30 packages in 1.76s\n",
      "Installed 213 packages in 724ms\n",
      "- accelerate==1.\n",
      "10.1\n",
      " +\n",
      "accelerate==1.10.0\n",
      " + aiohappyeyeballs==2.6.\n",
      "1\n",
      " + aiohttp==3.13.0\n",
      "+ aiosignal==1.4.0\n",
      " + alembic==1.16.5\n",
      "+ argcomplete==3.6.2\n",
      " + astor==0.8.1\n",
      " + authlib==\n",
      "1.6.5\n",
      " + bitsandbytes==0.46.1\n",
      " + blake3==1.0.\n",
      "7\n",
      " + blinker==1.9.0\n",
      " + brotli==1.1.0\n",
      " + build==1.3\n",
      ".0\n",
      " + cachecontrol==0.14.3\n",
      " + cachetools==6.2.0\n",
      " + cbor2==5.\n",
      "7.0\n",
      " + chardet==5.2.0\n",
      " + cleo==2.1.0\n",
      " + compressed-tensors==0.10.2\n",
      "+ crashtest==0.4.1\n",
      " - cryptography==46.0.2\n",
      " + cryptography==45.\n",
      "0.7\n",
      " + cupy-cuda12x==13.6.0\n",
      " + cyclopts==3.24.0\n",
      " + databricks-sdk==0.\n",
      "67.0\n",
      " + dataproperty==1.1.0\n",
      " + datasets==4.0.0\n",
      " + deepspeed==0.17.5\n",
      " + depyf==0\n",
      ".19.0\n",
      " - dill==0.4.0\n",
      " + dill==0.3.8\n",
      " + diskcache==5.6.3\n",
      "+ distlib==0.4.0\n",
      " + distro==1.9.0\n",
      " + dnspython==2.8.0\n",
      "+ docstring-parser==0.17.0\n",
      " + dulwich==0.24.2\n",
      " + email-validator==2.3.0\n",
      " + evaluate\n",
      "==0.4.6\n",
      " + exceptiongroup==1.3.0\n",
      " + fastapi-cli==0.0.13\n",
      " + fastapi-cloud-cli\n",
      "==0.3.1\n",
      " + fastjsonschema==2.21.2\n",
      " + fastmcp==2.12.4\n",
      " +\n",
      "fastrlock==0.8.3\n",
      " - filelock==3.13.1\n",
      " + filelock==3.20.0\n",
      " + findpython==\n",
      "0.7.0\n",
      " + flask==3.1.2\n",
      " + frozenlist==1.8.0\n",
      " - fsspec==2025.9\n",
      ".0\n",
      " + fsspec==2025.3.0\n",
      " + gguf==0.17.1\n",
      " + gitdb\n",
      "==4.0.12\n",
      " + gitpython==3.1.45\n",
      " + google-auth==2.41.1\n",
      "+ gunicorn==23.0.0\n",
      " + hf-transfer==0.1.8\n",
      "+ hjson==3.1.0\n",
      " + httpcore==1.0.9\n",
      " +\n",
      "httptools==0.6.4\n",
      " + httpx==0.28.1\n",
      " + httpx-sse\n",
      "==0.4.2\n",
      " + inflate64==1.0.3\n",
      " + iniconfig==2.1.0\n",
      " + installer==0.7.0\n",
      " + interegular==0.3.\n",
      "3\n",
      " + isodate==0.7.2\n",
      " + itsdangerous==2.2.0\n",
      "+ jaraco-classes==3.4.0\n",
      " + jaraco-context==6.0.1\n",
      " + jaraco-functools==4.3.0\n",
      " + jeepney\n",
      "==0.9.0\n",
      " + jiter==0.11.0\n",
      " + jsonlines==4.0.0\n",
      "+ jsonschema-path==0.3.4\n",
      " + kernels==0.10.2\n",
      " + keyring==25.6.0\n",
      " + lark\n",
      "==1.2.2\n",
      " + lazy-object-proxy==1.12.0\n",
      " + liger-kernel==0.6.1\n",
      " + llguidance\n",
      "==0.7.30\n",
      " - llvmlite==0.45.1\n",
      " + llvmlite==0.44.0\n",
      " + lm-eval==0.4.9\n",
      "+ lm-format-enforcer==0.10.12\n",
      " + lxml==6.0.2\n",
      " + mako\n",
      "==1.3.10\n",
      " + mbstrdecoder==1.1.4\n",
      " + mcp==1.16.0\n",
      " +\n",
      "mistral-common==1.8.5\n",
      " + mlflow==3.4.0\n",
      " + mlflow-skinny==3.4.0\n",
      " +\n",
      "mlflow-tracing==3.4.0\n",
      " + more-itertools==10.8.0\n",
      " + msgpack==1.1.2\n",
      " + msgspec==0.19\n",
      ".0\n",
      " + multidict==6.7.0\n",
      " - multiprocess==0.70.18\n",
      " + multiprocess==0.70.16\n",
      " +\n",
      "multivolumefile==0.2.3\n",
      " + nltk==3.9.2\n",
      " - numba==0.62.1\n",
      "+ numba==0.61.2\n",
      " + numexpr==2.13.1\n",
      " - nvidia-cublas-cu12==12.9.1.4\n",
      "+ nvidia-cublas-cu12==12.6.4.1\n",
      " - nvidia-cuda-cupti-cu12==12.9.79\n",
      " + nvidia-cuda-cupti-cu12==12\n",
      ".6.80\n",
      " - nvidia-cuda-nvrtc-cu12==12.9.86\n",
      " + nvidia-cuda-nvrtc-cu12==12.6.77\n",
      " -\n",
      "nvidia-cuda-runtime-cu12==12.9.79\n",
      " + nvidia-cuda-runtime-cu12==12.6.77\n",
      " - nvidia-cudnn-cu12==9.10.2\n",
      ".21\n",
      " + nvidia-cudnn-cu12==9.5.1.17\n",
      " - nvidia-cufft-cu12==11.4.1.4\n",
      "+ nvidia-cufft-cu12==11.3.0.4\n",
      " - nvidia-cufile-cu12==1.14.1.1\n",
      "+ nvidia-cufile-cu12==1.11.1.6\n",
      " - nvidia-curand-cu12==10.3.10.19\n",
      " +\n",
      "nvidia-curand-cu12==10.3.7.77\n",
      " - nvidia-cusolver-cu12==11.7.5.82\n",
      "+ nvidia-cusolver-cu12==11.7.1.2\n",
      " - nvidia-cusparse-cu12==12.5.10.65\n",
      " +\n",
      "nvidia-cusparse-cu12==12.5.4.2\n",
      " - nvidia-cusparselt-cu12==0.7.1\n",
      "+ nvidia-cusparselt-cu12==0.6.3\n",
      " + nvidia-ml-py==13.580.82\n",
      "- nvidia-nccl-cu12==2.27.3\n",
      " + nvidia-nccl-cu12==\n",
      "2.26.2\n",
      " - nvidia-nvjitlink-cu12==12.9.86\n",
      " +\n",
      "nvidia-nvjitlink-cu12==12.6.85\n",
      " - nvidia-nvtx-cu12==12.9.79\n",
      " +\n",
      "nvidia-nvtx-cu12==12.6.77\n",
      " + openai==2.2.0\n",
      " +\n",
      "openai-harmony==0.0.4\n",
      " + openapi-core==0.19.5\n",
      " + openapi-pydantic==0.5.1\n",
      "+ openapi-schema-validator==0.6.3\n",
      " + openapi-spec-validator==0.7.2\n",
      "+ opencv-python-headless==4.11.0.86\n",
      " + opentelemetry-api==1.37.0\n",
      " + opentelemetry-proto==1.37.\n",
      "0\n",
      " + opentelemetry-sdk==1.37.0\n",
      " + opentelemetry-semantic-conventions==0\n",
      ".58b0\n",
      " + outlines-core==0.2.10\n",
      " + parse==1.20.2\n",
      " +\n",
      "partial-json-parser==0.2.1.1.post6\n",
      " + pathable==0.4.4\n",
      " - pathos==0.3.4\n",
      " + pathos==0.3.2\n",
      " +\n",
      "pathvalidate==3.3.\n",
      "1\n",
      " + pbs-installer==2025.10.7\n",
      " + peft==0.17.0\n",
      " + pkginfo==1.12.1.2\n",
      " + pluggy==1.6.0\n",
      " + poetry==2.2\n",
      ".1\n",
      " + poetry-core==2.2.1\n",
      " + portalocker==3\n",
      ".2.0\n",
      " + prometheus-client==0.23.1\n",
      " + prometheus-fastapi-instrumentator==7.1.0\n",
      " + propcache==0.4.1\n",
      " + py-cpuinfo\n",
      "==9.0.0\n",
      " + py7zr==1.0.0\n",
      " + pyasn1-modules==0.4.2\n",
      "+ pybase64==1.4.2\n",
      " + pybcj==1.0.6\n",
      " + pycountry==24.6.1\n",
      " + pycryptodomex\n",
      "==3.23.0\n",
      " + pydantic-extra-types==2.10.6\n",
      " + pydantic-settings==2.11.0\n",
      "+ pyperclip==1.11.0\n",
      " + pyppmd==1.2.0\n",
      " + pyproject-hooks==1.2.0\n",
      " +\n",
      "pytablewriter==1.2.1\n",
      " + pytest==8.4.2\n",
      " + python-dotenv\n",
      "==1.1.1\n",
      " + python-json-logger==4.0.0\n",
      " + python-multipart==0.0.20\n",
      " + pyzstd==0.18.0\n",
      " + rapidfuzz==3.\n",
      "14.1\n",
      " + ray==2.49.2\n",
      " + regex==2025.9.18\n",
      "+ requests-toolbelt==1.0.0\n",
      " + rfc3339-validator==0.1.4\n",
      " +\n",
      "rich-rst==1.3.1\n",
      " + rich-toolkit==0.15.1\n",
      " +\n",
      "rignore==0.7.0\n",
      " + rouge-score==0.1.2\n",
      " +\n",
      "sacrebleu==2.5.1\n",
      " - sagemaker==2.252.0\n",
      "+ sagemaker==2.251.1\n",
      " + sagemaker-mlflow==0.1.0\n",
      " +\n",
      "secretstorage==3.4.0\n",
      " + sentencepiece==0.2.\n",
      "0\n",
      " + sentry-sdk==2.41.0\n",
      " + setproctitle==1.3.7\n",
      " -\n",
      "setuptools==80.9.0\n",
      " + setuptools==79.0.1\n",
      "+ smmap==5.0.2\n",
      " + soundfile==0.13.1\n",
      " + soxr==1.0.0\n",
      "+ sqlalchemy==2.0.43\n",
      " + sqlitedict==2.1.0\n",
      " +\n",
      "sqlparse==0.5.3\n",
      " + sse-starlette==3.0.2\n",
      " + tabledata==1.3.4\n",
      "+ tcolorpy==0.1.7\n",
      " + tenacity==9.1.2\n",
      " +\n",
      "texttable==1.7.0\n",
      " + tiktoken==0.12.0\n",
      "+ tokenizers==0.21.4\n",
      " + tomlkit==0.13.3\n",
      "- torch==2.8.0+cu129\n",
      " + torch==2.7.1\n",
      " - torchaudio\n",
      "==2.8.0+cu129\n",
      " + torchaudio==2.7.1\n",
      " - torchvision==\n",
      "0.23.0+cu129\n",
      " + torchvision==0.22.1\n",
      " + tqdm-multiprocess==0.0.11\n",
      "+ transformers==4.55.0\n",
      " - triton==3.4.0\n",
      " + triton==3.3.1\n",
      "+ triton-kernels==1.0.0 (from git+https://github.com/triton-lang/triton.git@3419eedd7749f59a28af65466561623d400d3212#subdirectory=python/triton_kernels)\n",
      " + trl==0.21.0\n",
      " +\n",
      "trove-classifiers==2025.9.11.17\n",
      " + typepy==1.3.4\n",
      " + uvloop\n",
      "==0.21.0\n",
      " + virtualenv==20.34.0\n",
      " + vllm==0.10.\n",
      "1\n",
      " + watchfiles==1.1.0\n",
      " +\n",
      "websockets==15.0.1\n",
      " - werkzeug==3.1.3\n",
      " + werkzeug\n",
      "==3.1.1\n",
      " + word2number==1.1\n",
      " +\n",
      "xformers==0.0.31\n",
      " + xgrammar==0.1.21\n",
      " +\n",
      "xmltodict==1.0.2\n",
      " + xxhash==3.6.0\n",
      " + yarl==1.22.0\n",
      "+ yq==3.4.3\n",
      " + zstandard==0.25.0\n",
      "2025-10-09 15:17:02,352 - __main__ - INFO - Set random seed to 42\n",
      "2025-10-09 15:17:02,352 - __main__ - INFO - ==================================================\n",
      "2025-10-09 15:17:02,352 - __main__ - INFO - Starting Supervised Fine-Tuning\n",
      "2025-10-09 15:17:02,352 - __main__ - INFO - ==================================================\n",
      "2025-10-09 15:17:02,352 - __main__ - INFO - \n",
      "üåÄüåÄüåÄ MODALITY: text üåÄüåÄüåÄ\n",
      "2025-10-09 15:17:02,352 - __main__ - INFO - Model parameters: ModelConfig(model_name_or_path='Qwen/Qwen3-0.6B', model_revision='main', torch_dtype='bfloat16', trust_remote_code=False, attn_implementation='eager', use_peft=True, lora_r=16, lora_alpha=16, lora_dropout=0.05, lora_target_modules='all-linear', lora_target_parameters=None, lora_modules_to_save=['lm_head', 'embed_tokens'], lora_task_type='CAUSAL_LM', use_rslora=False, use_dora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)\n",
      "2025-10-09 15:17:02,352 - __main__ - INFO - Script parameters: ScriptArguments(dataset_id_or_path='/opt/ml/input/data/train/finance-instruct-500k.jsonl', dataset_splits='train', tokenizer_name_or_path='Qwen/Qwen3-0.6B', processor_name_or_path=None, spectrum_config_path=None, max_seq_length=4096, mxfp4=False, use_liger=False, modality_type='text', run_evaluation=True, eval_max_samples=100, eval_max_new_tokens=512)\n",
      "2025-10-09 15:17:02,352 - __main__ - INFO - Training parameters: SFTConfig(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "activation_offloading=False,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "assistant_only_loss=False,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "chat_template_path=None,\n",
      "completion_only_loss=None,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "dataset_kwargs=None,\n",
      "dataset_num_proc=None,\n",
      "dataset_text_field=text,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eos_token=<EOS_TOKEN>,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_packing=None,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.NO,\n",
      "eval_use_gather_object=False,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs={'use_reentrant': True},\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_revision=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "liger_kernel_config=None,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/opt/ml/output/data/qwen3-06b/runs/Oct09_15-17-02_algo-1,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=5,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.COSINE,\n",
      "max_grad_norm=1.0,\n",
      "max_length=1024,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "model_init_kwargs=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=/opt/ml/output/data/qwen3-06b,\n",
      "overwrite_output_dir=False,\n",
      "packing=True,\n",
      "packing_strategy=bfd,\n",
      "pad_to_multiple_of=None,\n",
      "pad_token=<PAD_TOKEN>,\n",
      "padding_free=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['mlflow'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=fine-tuning-run-1,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=SaveStrategy.EPOCH,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "tf32=True,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.1,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "2025-10-09 15:17:02,352 - __main__ - INFO - Loading JSONL dataset from /opt/ml/input/data/train/finance-instruct-500k.jsonl\n",
      "************************************\n",
      "LISTING /opt/ml/input/data/training/\n",
      "2025-10-09 15:17:02,352 - __main__ - ERROR - Failed to load datasets: [Errno 2] No such file or directory: '/opt/ml/intput/data/training'\n",
      "Generating train split:   0%|          | 0/518185 [00:00<?, ? examples/s]\n",
      "Generating train split:   2%|‚ñè         | 11151/518185 [00:00<00:05, 98886.17 examples/s]\n",
      "Generating train split:   4%|‚ñç         | 21658/518185 [00:00<00:06, 79074.96 examples/s]\n",
      "Generating train split:   9%|‚ñâ         | 46006/518185 [00:00<00:04, 104928.35 examples/s]\n",
      "Generating train split:  13%|‚ñà‚ñé        | 69742/518185 [00:00<00:03, 112448.02 examples/s]\n",
      "Generating train split:  16%|‚ñà‚ñã        | 84273/518185 [00:01<00:05, 73885.23 examples/s]\n",
      "Generating train split:  24%|‚ñà‚ñà‚ñç       | 124083/518185 [00:01<00:03, 120568.50 examples/s]\n",
      "Generating train split:  31%|‚ñà‚ñà‚ñà       | 160956/518185 [00:01<00:02, 166129.45 examples/s]\n",
      "Generating train split:  39%|‚ñà‚ñà‚ñà‚ñâ      | 203359/518185 [00:01<00:01, 217601.85 examples/s]\n",
      "Generating train split:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 241861/518185 [00:01<00:01, 252043.02 examples/s]\n",
      "Generating train split:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 281272/518185 [00:01<00:00, 285056.52 examples/s]\n",
      "Generating train split:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 329293/518185 [00:01<00:00, 247488.66 examples/s]\n",
      "Generating train split:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 370281/518185 [00:01<00:00, 255323.10 examples/s]\n",
      "Generating train split:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 405478/518185 [00:02<00:00, 230058.03 examples/s]\n",
      "Generating train split:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 454234/518185 [00:02<00:00, 203945.07 examples/s]\n",
      "Generating train split:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 489287/518185 [00:02<00:00, 210133.95 examples/s]\n",
      "Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 518185/518185 [00:02<00:00, 218481.92 examples/s]\n",
      "Generating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 518185/518185 [00:02<00:00, 190812.67 examples/s]\n",
      "Map:   0%|          | 0/100 [00:00<?, ? examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 13287.41 examples/s]\n",
      "2025-10-09 15:17:07,299 - __main__ - WARNING - Dataset has only 100 samples, using 90/10 split\n",
      "2025-10-09 15:17:07,301 - __main__ - INFO - Loading tokenizer from Qwen/Qwen3-0.6B\n",
      "2025-10-09 15:17:08,315 - __main__ - INFO - \n",
      "ü™´üîãü™´üîãü™´üîãü™´üîãü™´üîãü™´üîãü™´üîãü™´ü™´üîãü™´üîãü™´üîãü™´üîãü™´üîã\n",
      "ü™´   CONFIGURING PEFT    ü™´\n",
      "ü™´üîãü™´üîãü™´üîãü™´üîãü™´üîãü™´üîãü™´üîãü™´ü™´üîãü™´üîãü™´üîãü™´üîãü™´üîã\n",
      "2025-10-09 15:17:08,315 - __main__ - INFO - ‚ÜîÔ∏è Loading standard model\n",
      "Qwen/Qwen3-0.6B {'revision': 'main', 'trust_remote_code': False, 'attn_implementation': 'eager', 'torch_dtype': torch.bfloat16, 'low_cpu_mem_usage': True}\n",
      "2025-10-09 15:17:12,406 - __main__ - WARNING - ü§ñ No Spectrum config provided - using standard training\n",
      "/usr/local/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:453: UserWarning: Padding-free training is enabled, but the attention implementation is not set to 'flash_attention_2'. Padding-free training flattens batches into a single sequence, and 'flash_attention_2' is the only known attention mechanism that reliably supports this. Using other implementations may lead to unexpected behavior. To ensure compatibility, set `attn_implementation='flash_attention_2'` in the model configuration, or verify that your attention mechanism can handle flattened sequences.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:495: UserWarning: You are using packing, but the attention implementation is not set to 'flash_attention_2' or 'kernels-community/vllm-flash-attn3'. Packing flattens batches into a single sequence, and Flash Attention is the only known attention mechanisms that reliably support this. Using other implementations may lead to cross-contamination between batches. To avoid this, either disable packing by setting `packing=False`, or set `attn_implementation='flash_attention_2'` or `attn_implementation='kernels-community/vllm-flash-attn3'` in the model configuration.\n",
      "  warnings.warn(\n",
      "Tokenizing train dataset:   0%|          | 0/90 [00:00<?, ? examples/s]\n",
      "Tokenizing train dataset:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 55/90 [00:00<00:00, 541.55 examples/s]\n",
      "Tokenizing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [00:00<00:00, 591.00 examples/s]\n",
      "Packing train dataset:   0%|          | 0/90 [00:00<?, ? examples/s]\n",
      "Packing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [00:00<00:00, 15962.09 examples/s]\n",
      "Tokenizing eval dataset:   0%|          | 0/10 [00:00<?, ? examples/s]\n",
      "Tokenizing eval dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 588.83 examples/s]\n",
      "Packing eval dataset:   0%|          | 0/10 [00:00<?, ? examples/s]\n",
      "Packing eval dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 3675.02 examples/s]\n",
      "[2025-10-09 15:17:14,766] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "df: /root/.triton/autotune: No such file or directory\n",
      "[2025-10-09 15:17:20,695] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "trainable params: 321,257,472 || all params: 917,307,392 || trainable%: 35.0218\n",
      "2025-10-09 15:17:20,843 - __main__ - INFO - Starting training at 2025-10-09 15:17:20 for 1 epochs\n",
      "2025/10/09 15:17:22 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "0%|          | 0/40 [00:00<?, ?it/s]\n",
      "2%|‚ñé         | 1/40 [00:00<00:38,  1.00it/s]\n",
      "5%|‚ñå         | 2/40 [00:01<00:22,  1.69it/s]\n",
      "8%|‚ñä         | 3/40 [00:01<00:17,  2.11it/s]\n",
      "10%|‚ñà         | 4/40 [00:01<00:14,  2.48it/s]\n",
      "12%|‚ñà‚ñé        | 5/40 [00:02<00:13,  2.63it/s]\n",
      "{'loss': 2.247, 'grad_norm': 4.2028398513793945, 'learning_rate': 0.0001, 'num_tokens': 4552.0, 'mean_token_accuracy': 0.5628434896469117, 'epoch': 0.12}\n",
      "12%|‚ñà‚ñé        | 5/40 [00:02<00:13,  2.63it/s]\n",
      "15%|‚ñà‚ñå        | 6/40 [00:03<00:17,  1.92it/s]\n",
      "18%|‚ñà‚ñä        | 7/40 [00:03<00:14,  2.23it/s]\n",
      "20%|‚ñà‚ñà        | 8/40 [00:03<00:12,  2.52it/s]\n",
      "22%|‚ñà‚ñà‚ñé       | 9/40 [00:03<00:11,  2.76it/s]\n",
      "25%|‚ñà‚ñà‚ñå       | 10/40 [00:04<00:10,  2.95it/s]\n",
      "{'loss': 2.0531, 'grad_norm': 3.5275046825408936, 'learning_rate': 9.53153893518325e-05, 'num_tokens': 8977.0, 'mean_token_accuracy': 0.5594188928604126, 'epoch': 0.25}\n",
      "25%|‚ñà‚ñà‚ñå       | 10/40 [00:04<00:10,  2.95it/s]\n",
      "28%|‚ñà‚ñà‚ñä       | 11/40 [00:04<00:12,  2.38it/s]\n",
      "30%|‚ñà‚ñà‚ñà       | 12/40 [00:05<00:11,  2.53it/s]\n",
      "32%|‚ñà‚ñà‚ñà‚ñé      | 13/40 [00:05<00:09,  2.72it/s]\n",
      "35%|‚ñà‚ñà‚ñà‚ñå      | 14/40 [00:05<00:09,  2.81it/s]\n",
      "38%|‚ñà‚ñà‚ñà‚ñä      | 15/40 [00:06<00:08,  3.00it/s]\n",
      "{'loss': 1.7411, 'grad_norm': 3.047879219055176, 'learning_rate': 8.213938048432697e-05, 'num_tokens': 13712.0, 'mean_token_accuracy': 0.6058812856674194, 'epoch': 0.38}\n",
      "38%|‚ñà‚ñà‚ñà‚ñä      | 15/40 [00:06<00:08,  3.00it/s]\n",
      "40%|‚ñà‚ñà‚ñà‚ñà      | 16/40 [00:06<00:11,  2.17it/s]\n",
      "42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/40 [00:07<00:09,  2.46it/s]\n",
      "45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/40 [00:07<00:08,  2.60it/s]\n",
      "48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 19/40 [00:07<00:07,  2.73it/s]\n",
      "50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 20/40 [00:08<00:06,  2.93it/s]\n",
      "{'loss': 1.4217, 'grad_norm': 3.1883997917175293, 'learning_rate': 6.294095225512603e-05, 'num_tokens': 18361.0, 'mean_token_accuracy': 0.65356285572052, 'epoch': 0.5}\n",
      "50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 20/40 [00:08<00:06,  2.93it/s]\n",
      "52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 21/40 [00:08<00:08,  2.32it/s]\n",
      "55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 22/40 [00:08<00:06,  2.59it/s]\n",
      "57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 23/40 [00:09<00:06,  2.72it/s]\n",
      "60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 24/40 [00:09<00:05,  2.93it/s]\n",
      "62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 25/40 [00:09<00:04,  3.01it/s]\n",
      "{'loss': 1.5443, 'grad_norm': 3.239744186401367, 'learning_rate': 4.131759111665349e-05, 'num_tokens': 22564.0, 'mean_token_accuracy': 0.6221465587615966, 'epoch': 0.62}\n",
      "62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 25/40 [00:10<00:04,  3.01it/s]\n",
      "65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 26/40 [00:10<00:05,  2.34it/s]\n",
      "68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 27/40 [00:10<00:04,  2.60it/s]\n",
      "70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 28/40 [00:11<00:04,  2.77it/s]\n",
      "72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 29/40 [00:11<00:03,  2.97it/s]\n",
      "75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 30/40 [00:11<00:03,  2.96it/s]\n",
      "{'loss': 1.4139, 'grad_norm': 2.70681095123291, 'learning_rate': 2.132117818244771e-05, 'num_tokens': 27010.0, 'mean_token_accuracy': 0.6558228850364685, 'epoch': 0.75}\n",
      "75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 30/40 [00:12<00:03,  2.96it/s]\n",
      "78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 31/40 [00:12<00:04,  2.05it/s]\n",
      "80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 32/40 [00:12<00:03,  2.28it/s]\n",
      "82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 33/40 [00:13<00:02,  2.55it/s]\n",
      "85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 34/40 [00:13<00:02,  2.78it/s]\n",
      "88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 35/40 [00:13<00:01,  2.98it/s]\n",
      "{'loss': 1.4753, 'grad_norm': 3.594398260116577, 'learning_rate': 6.698729810778065e-06, 'num_tokens': 31209.0, 'mean_token_accuracy': 0.6431285619735718, 'epoch': 0.88}\n",
      "88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 35/40 [00:13<00:01,  2.98it/s]\n",
      "90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 36/40 [00:14<00:01,  2.56it/s]\n",
      "92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 37/40 [00:14<00:01,  2.79it/s]\n",
      "95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 38/40 [00:14<00:00,  2.84it/s]\n",
      "98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 39/40 [00:15<00:00,  2.88it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:15<00:00,  2.92it/s]\n",
      "{'loss': 1.3623, 'grad_norm': 2.7604434490203857, 'learning_rate': 1.9026509541272275e-07, 'num_tokens': 36008.0, 'mean_token_accuracy': 0.6602140188217163, 'epoch': 1.0}\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:15<00:00,  2.92it/s]\n",
      "{'train_runtime': 21.4691, 'train_samples_per_second': 1.863, 'train_steps_per_second': 1.863, 'train_loss': 1.6573424935340881, 'epoch': 1.0}\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:20<00:00,  2.92it/s]\n",
      "üèÉ View run fine-tuning-run-1 at: https://us-east-1.experiments.sagemaker.aws/#/experiments/8/runs/f132794cacac41799d32b6b5e2c923eb\n",
      "üß™ View experiment at: https://us-east-1.experiments.sagemaker.aws/#/experiments/8\n",
      "2025/10/09 15:17:44 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/09 15:17:44 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:21<00:00,  1.84it/s]\n",
      "***** train metrics *****\n",
      "total_flos               =   121962GF\n",
      "  train_loss               =     1.6573\n",
      "  train_runtime            = 0:00:21.46\n",
      "  train_samples            =         90\n",
      "  train_samples_per_second =      1.863\n",
      "  train_steps_per_second   =      1.863\n",
      "2025-10-09 15:17:44,335 - __main__ - INFO - Saving PEFT model\n",
      "2025-10-09 15:17:45,927 - __main__ - INFO - PEFT adapter saved to /opt/ml/model/Qwen/Qwen3-0.6B/peft\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "2025-10-09 15:17:46,383 - __main__ - INFO - Tokenizer saved to /opt/ml/model/Qwen/Qwen3-0.6B/peft\n",
      "2025-10-09 15:17:46,383 - __main__ - INFO - Training completed successfully in 0:00:25.540220\n",
      "2025-10-09 15:17:46,383 - __main__ - INFO - ==================================================\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "2025/10/09 15:18:06 INFO mlflow.transformers: Overriding save_pretrained to False for PEFT models, following the Transformers behavior. The PEFT adaptor and config will be saved, but the base model weights will not and reference to the HuggingFace Hub repository will be logged instead.\n",
      "2025/10/09 15:18:07 INFO mlflow.transformers: Skipping saving pretrained model weights to disk as the save_pretrained argumentis set to False. The reference to the HuggingFace Hub repository Qwen/Qwen3-0.6B will be logged instead.\n",
      "2025/10/09 15:18:07 INFO mlflow.transformers: A local checkpoint path or PEFT model is given as the `transformers_model`. To avoid loading the full model into memory, we don't infer the pip requirement for the model. Instead, we will use the default requirements, but it may not capture all required pip libraries for the model. Consider providing the pip requirements explicitly.\n",
      "2025/10/09 15:18:08 WARNING mlflow.transformers.model_io: Could not specify device parameter for this pipeline type.Falling back to loading the model with the default device.\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n",
      "2025/10/09 15:18:10 WARNING mlflow.transformers: params provided to the `predict` method will override the inference configuration saved with the model. If the params provided are not valid for the pipeline, MlflowException will be raised.\n",
      "2025/10/09 15:18:32 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "üèÉ View run fine-tuning-run-1 at: https://us-east-1.experiments.sagemaker.aws/#/experiments/8/runs/f132794cacac41799d32b6b5e2c923eb\n",
      "üß™ View experiment at: https://us-east-1.experiments.sagemaker.aws/#/experiments/8\n",
      "2025/10/09 15:18:32 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/10/09 15:18:32 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "2025-10-09 15:18:36,033 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2025-10-09 15:18:36,033 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2025-10-09 15:18:36,033 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2025-10-09 15:18:45 Uploading - Uploading generated training model\n",
      "2025-10-09 15:19:36 Completed - Resource retained for reuse\n",
      "Training seconds: 567\n",
      "Billable seconds: 567\n"
     ]
    }
   ],
   "source": [
    "pytorch_estimator = PyTorch(\n",
    "    image_uri=pytorch_image_uri,\n",
    "    entry_point=\"train.sh\",  # Adapted bash script to train using accelerate on SageMaker - Multi-GPU\n",
    "    source_dir=\"scripts\",\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=job_name,\n",
    "    role=role,\n",
    "    volume_size=300,\n",
    "    py_version=\"py312\",\n",
    "    keep_alive_period_in_seconds=3600,\n",
    "    environment=environment,\n",
    "    sagemaker_session=sess,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "# fit or train\n",
    "pytorch_estimator.fit({\"train\": uploaded_s3_uri}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aecced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_model_data_uri = pytorch_estimator.model_data\n",
    "# print(f\"Fine-tuned model location: {s3_model_data_uri}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
