{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f946b5",
   "metadata": {},
   "source": [
    "## Fine-tuning LLMs and Experiment Tracking with MLflow ðŸ§ª\n",
    "\n",
    "Most of our MLflow configurations exist in our training script `sft.py`. This is where we import the MLflow library, set our tracking server, name our experiments and runs and log artifiacts, parameters, and metrics. MLflow has direct integration with Huggingface Transformers library to make it easy to setup.\n",
    "\n",
    "## Setting Up MLflow\n",
    "\n",
    "Getting started with MLflow is straightforward. You can install MLflow using pip:\n",
    "\n",
    "```bash\n",
    "pip install mlflow\n",
    "pip install mlflow-sagemaker\n",
    "```\n",
    "\n",
    "The second package is needed to set a tracking server in SageMaker with an Amazon Resource Name (ARN). Once these two packages are installed you import the mlflow library and set the tracking URI to your SageMaker tracking server and name your experiment.\n",
    "\n",
    "```python\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"your_sagemaker_tracking_uri\")\n",
    "mlflow.set_experiment(\"your_experiment_name\")\n",
    "```\n",
    "\n",
    "Next you need to start a run. A run can be a fine-tuning job or an evaluation job. Runs can be nested with a parent child relationship to remember which jobs are related to each other. Once you have initiated a run you can log different items to MLflow.\n",
    "\n",
    "```python\n",
    "with mlflow.start_run(run_name='training-job-1') as run:\n",
    "    trainer.train()\n",
    "    mlflow.log_metrics('loss': 0.05)\n",
    "    mlflow.log_param(\"learning_rate\", 0.01)\n",
    "    mlflow.log_artifact('recipe.yaml')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce40054-610a-4acc-a546-943893f293c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -r requirements-fine-tuning.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791e72e-82b5-4f8e-a7fe-700e8afdeba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# from PIL import Image\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c673a9-5b9f-47e0-92cf-bb97486b3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "\n",
    "# from sagemaker.local import LocalSession\n",
    "# sess = LocalSession() #sagemaker.Session(boto3.Session(region_name=region))\n",
    "# sess.config = {\"local\": {\"local_code\": True}}\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9786901-b012-41ff-a98a-b16e5f60ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145954cd",
   "metadata": {},
   "source": [
    "## Data Preparation for Supervised Fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bdc257",
   "metadata": {},
   "source": [
    "### [Finance-Instruct-500k](https://huggingface.co/datasets/Josephgflowers/Finance-Instruct-500k)\n",
    "\n",
    "**Finance-Instruct-500k** is a large-scale dataset with about **518,000 entries** focused on the financial domain. It spans topics such as investments, banking, markets, accounting, and corporate finance, offering a wide variety of instructionâ€“response examples.\n",
    "\n",
    "**Data Format & Structure**:\n",
    "\n",
    "- Distributed in **JSON** format, with simple conversion to Parquet.\n",
    "- Contains a single `train` split with ~518k records.\n",
    "- Each record includes:\n",
    "  - `system` â€“ context or metadata for the task\n",
    "  - `user` â€“ the financial prompt or query\n",
    "  - `assistant` â€“ the corresponding response\n",
    "\n",
    "**License**: Released under the **Apache-2.0** license.\n",
    "\n",
    "**Applications**:\n",
    "\n",
    "The dataset can support finance-focused tasks such as:\n",
    "\n",
    "- Financial question answering\n",
    "- Market and investment analysis\n",
    "- Topic and sentiment classification\n",
    "- Financial entity extraction and document understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc26be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed7366",
   "metadata": {},
   "source": [
    "**Preparing Your Dataset in `messages` format**\n",
    "\n",
    "This section walks you through creating a conversation-style datasetâ€”the required `messages` formatâ€”for directly training LLMs using SageMaker AI.\n",
    "\n",
    "**What Is the `messages` Format?**\n",
    "\n",
    "The `messages` format structures instances as chat-like exchanges, wrapping each conversation turn into a role-labeled JSON array. Itâ€™s widely used by frameworks like TRL.\n",
    "\n",
    "Example entry:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "    { \"role\": \"user\", \"content\": \"How do I bake sourdough?\" },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"First, you need to create a starter by...\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3921310",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Josephgflowers/Finance-Instruct-500k\"\n",
    "dataset = load_dataset(\n",
    "    dataset_name, split=\"train[:100]\"\n",
    ")  # just a toy example with 100 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pp(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ec6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"total number of fine-tunable samples: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f7f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_messages(row):\n",
    "    system_content = \"You are a financial reasoning assistant. Read the userâ€™s query, restate the key data, and solve step by step. Show calculations clearly, explain any rounding or adjustments, and present the final answer in a concise and professional manner.\"\n",
    "    user_content = row[\"user\"]\n",
    "    assistant_content = row[\"assistant\"]\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": user_content},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_content},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "dataset = dataset.map(convert_to_messages, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8887de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_parent_path = os.path.join(os.getcwd(), \"data\")\n",
    "os.makedirs(dataset_parent_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = os.path.join(\n",
    "    dataset_parent_path,\n",
    "    \"finance-instruct-500k.jsonl\",\n",
    ")\n",
    "dataset.to_json(dataset_filename, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8bf70",
   "metadata": {},
   "source": [
    "#### Upload file to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s3_uri = f\"s3://{sess.default_bucket()}/dataset\"\n",
    "\n",
    "uploaded_s3_uri = S3Uploader.upload(\n",
    "    local_path=dataset_filename, desired_s3_uri=data_s3_uri\n",
    ")\n",
    "print(f\"Uploaded {dataset_filename} to:\")\n",
    "print(uploaded_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb0000",
   "metadata": {},
   "source": [
    "## Fine-Tune LLMs using SageMaker `Estimator`/`ModelTrainer`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80210ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from getpass import getpass\n",
    "import yaml\n",
    "from jinja2 import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d2e06",
   "metadata": {},
   "source": [
    "### Training using `PyTorch` Estimator\n",
    "\n",
    "**Training Using `PyTorch` Estimator**\n",
    "Leverages the official PyTorch SageMaker container to run a custom training script using the Accelerate and DeepSpeed libraries. This option is ideal for users who want full control over the training pipeline\n",
    "\n",
    "---\n",
    "\n",
    "**Observability**: SageMaker AI has [SageMaker MLflow](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html) which enables you to accelerate generative AI by making it easier to track experiments and monitor performance of models and AI applications using a single tool.\n",
    "\n",
    "You can choose to include MLflow as a part of your training workflow to track your model fine-tuning metrics in realtime by simply specifying a **mlflow** tracking arn.\n",
    "\n",
    "Optionally you can also report to : **tensorboard**, **wandb**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd327996",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_SERVER_ARN = 'arn:aws:sagemaker:us-east-1:198346569064:mlflow-tracking-server/vlm-finetuning-server'  # or \"arn:aws:sagemaker:us-west-2:<account-id>:mlflow-tracking-server/<server-name>\"\n",
    "\n",
    "if MLFLOW_TRACKING_SERVER_ARN:\n",
    "    reports_to = \"mlflow\"\n",
    "else:\n",
    "    reports_to = \"tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 'qwen3-06b-lora-ft-finance'  # cannot use '.' in name\n",
    "instance_type = \"ml.g5.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MLFLOW_TRACKING_SERVER_ARN:\n",
    "    environment = {\n",
    "        \"MLFLOW_EXPERIMENT_NAME\": job_name,\n",
    "        \"MLFLOW_TAGS\": '{\"source.job\": \"sm-training-jobs\", \"source.type\": \"sft\", \"source.framework\": \"pytorch\"}',\n",
    "        \"HF_TOKEN\": hf_token,\n",
    "        \"MLFLOW_TRACKING_URI\": MLFLOW_TRACKING_SERVER_ARN,\n",
    "    }\n",
    "else:\n",
    "    environment = {\"HF_TOKEN\": hf_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7868fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_image_uri = f\"763104351884.dkr.ecr.{region}.amazonaws.com/pytorch-training:2.8.0-gpu-py312-cu129-ubuntu22.04-sagemaker\"\n",
    "print(f\"Using image: {pytorch_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_run_description = '''\n",
    "    AIops MLflow Workshop\n",
    "\n",
    "    This section shows how to fine-tune a model and track experiments with MLflow tracking UI server. \n",
    "    Once models are fine-tuned they can be evaluated using MLflow built in metrics and LLM-as-a-judge\n",
    "    functionality. \n",
    "\n",
    "    The fine-tuned model is Qwen3 0.6B and fine-tuned on a finance reasoning dataset.\n",
    "    '''\n",
    "\n",
    "hyperparameters = {\n",
    "    \"config\": \"qwen3-0.6b.yaml\",\n",
    "    \"mlflow_run_description\": mlflow_run_description,\n",
    "    # \"mlflow_experiment_name\": job_name,\n",
    "    # \"mlflow_tags\": '{\"source.job\": \"sm-training-jobs\", \"source.type\": \"sft\", \"source.framework\": \"pytorch\"}',\n",
    "    # \"hf_token\": hf_token,\n",
    "    # \"mlflow_tracking_server\": MLFLOW_TRACKING_SERVER_ARN,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe43f9a",
   "metadata": {},
   "source": [
    "#### Training strategy: `PeFT/LoRA`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a32ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_estimator = PyTorch(\n",
    "    image_uri=pytorch_image_uri,\n",
    "    entry_point=\"train.sh\",  # Adapted bash script to train using accelerate on SageMaker - Multi-GPU\n",
    "    source_dir=\"scripts\",\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=job_name,\n",
    "    role=role,\n",
    "    volume_size=300,\n",
    "    py_version=\"py312\",\n",
    "    keep_alive_period_in_seconds=3600,\n",
    "    environment=environment,\n",
    "    sagemaker_session=sess,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "# fit or train\n",
    "pytorch_estimator.fit({\"train\": uploaded_s3_uri}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aecced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_model_data_uri = pytorch_estimator.model_data\n",
    "# print(f\"Fine-tuned model location: {s3_model_data_uri}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
