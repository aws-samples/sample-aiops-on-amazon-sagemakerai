{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Tracing for AI Agents \n",
    "\n",
    "This section we will show you how to use MLflow to see how Agent is thinking, selecting and executing tools to get the final response. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data & MLflow Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.0\n",
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "from data.data import log_data_set, log_data\n",
    "from data.solution_book import knowledge_base\n",
    "\n",
    "import sagemaker_mlflow\n",
    "import mlflow\n",
    "\n",
    "print(sagemaker_mlflow.__version__)\n",
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The latest MLflow version with Sagemaker AI is MLflow 3.0 and python 3.9 or later, You can find more information [here](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html). To make sure you can successfuly run use the compatible version, make sure you install `sagemaker_mlflow==0.1.0` and `mlflow=3.0.0`\n",
    "\n",
    "Once you have started the Tracking Servers, you can copy the tracking_server_arn and use that to set the tracking uri. So that you can monitor your Agent experiment on the user interface. You can find it right here:\n",
    "\n",
    "![MLflow Tracking Server ARN](./static/agent/2_agent_mlflow/mlflow_tracking_server_arn.png) \n",
    "\n",
    "Now you can put your tracking server arn to the following place holder string, you can give any experiment name, in this workshop, we will use experiment name: agent-mlflow-demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://agent-mlflow/1', creation_time=1758206034961, experiment_id='1', last_update_time=1758206034961, lifecycle_stage='active', name='agent-mlflow-demo', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_server_arn = \"\" \n",
    "experiment_name = \"agent-mlflow-demo\"\n",
    "mlflow.set_tracking_uri(tracking_server_arn) \n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets open the MLflow and take a look on the User Interface \n",
    "\n",
    "![Open MLflow](./static/agent/2_agent_mlflow/open_mlflow.png) \n",
    "\n",
    "Click ***Open MLflow***, you will get into the MLflow UI page, here you can see your **agent-mlflow-demo** under Experiments section on the top left "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Tracing for LangGraph\n",
    "\n",
    "Let's use the same example we did in the Agent section, before we show trace, let's set up the auto tracing for LangGraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `mlflow.langchain.autolog()` is a function within the MLflow LangChain flavor that enables automatic logging of crucial details about LangChain models and their execution. This feature simplifies experiment tracking and analysis by eliminating the need for explicit logging statements. By default, `mlflow.langchain.autolog()`automatically logs traces of your LangChain components, providing a visual representation of data flow through chains, agents, and retrievers. This includes invocations of methods like invoke, batch, stream, ainvoke, abatch, astream, get_relevant_documents (for retrievers), and `__call__` (for Chains and AgentExecutors).\n",
    "\n",
    "> For **Strands Agents**, you can use `mlflow.strands.autolog`. However, this only support for MLflow version great than 3.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will the exact same code we showed for LangGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 17:43:40 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: 2 validation errors for ChatMessage\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=[{'type': 'tool_use', 'na...AHhtWz0QzWx-VRT_Xr93w'}], input_type=list]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "content.list[tagged-union[TextContentPart,ImageContentPart,AudioContentPart]].0\n",
      "  Input tag 'tool_use' found using 'type' does not match any of the expected tags: 'text', 'image_url', 'input_audio' [type=union_tag_invalid, input_value={'type': 'tool_use', 'nam...gAHhtWz0QzWx-VRT_Xr93w'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/union_tag_invalid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Check network connectivity between client and server\n",
      "2. Verify if the server is running and accessible\n",
      "3. Increase the connection timeout settings\n",
      "4. Check for firewall rules blocking the connection\n",
      "5. Monitor network latency and bandwidth\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool \n",
    "def log_identifier(ticket_id: str) -> str:\n",
    "    \"\"\"Get error type from ticket number\n",
    "\n",
    "    Args:\n",
    "        ticket_id: ticket id\n",
    "\n",
    "    Returns:\n",
    "        an error type\n",
    "\n",
    "    \"\"\"\n",
    "    if ticket_id not in log_data_set:\n",
    "        return \"ticket id not found in the database\"\n",
    "    \n",
    "    for item in log_data:\n",
    "        if item[\"id\"] == ticket_id:\n",
    "            return item['error_name']\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def information_retriever(error_type: str) -> str:\n",
    "    \"\"\"Retriever error solution based on error type\n",
    "\n",
    "    Args:\n",
    "        error_type: user input error type\n",
    "    \n",
    "    Returns:\n",
    "        a str of steps \n",
    "    \"\"\"\n",
    "\n",
    "    if error_type not in knowledge_base.keys():\n",
    "        return \"error type not found in the knowledge base, please use your own knowledge\"\n",
    "    \n",
    "    return knowledge_base[error_type]\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model= \"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    model_provider=\"bedrock_converse\",\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an expert a resolving ETL errors. You are equiped with two tools: \n",
    "1. log_identifier: Get error type from ticket number\n",
    "2. information_retriever: Retriever error solution based on error type\n",
    "\n",
    "You will use the ticket ID to gather information about the error using the log_identifier tool. \n",
    "Then you should search the database for information on how to resolve the error using the information_retriever tool\n",
    "\n",
    "Return ONLY the numbered steps without any introduction or conclusion. Format as:\n",
    "1. step 1 text\n",
    "2. step 2 text\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools= [log_identifier, information_retriever], \n",
    "    prompt=system_prompt\n",
    ")\n",
    "\n",
    "def get_langGraph_agent_response(ticket_id = 'TICKET-001'):\n",
    "    # Prepare input for the agent\n",
    "    agent_input = {\"messages\": [{\"role\": \"user\", \"content\": ticket_id}]}\n",
    "    response = agent.invoke(agent_input)\n",
    "    return response \n",
    "\n",
    "langGraph_agent_response = get_langGraph_agent_response(ticket_id = 'TICKET-001')\n",
    "print(langGraph_agent_response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when you can invoke the Agent to get the results for TICKET-001\n",
    "\n",
    ":::code{showCopyAction=true showLineNumbers=true language=python}\n",
    "langGraph_agent_response = get_langGraph_agent_response(ticket_id = 'TICKET-001')\n",
    "print(langGraph_agent_response)\n",
    ":::\n",
    "\n",
    "You will see the tracing showing in the UI, when you have more results, you will see more traces in the dashboard\n",
    "\n",
    "![MLflow Trace](./static/agent/2_agent_mlflow/trace-example.png) \n",
    "\n",
    "When you click into the Request ID, you can see all the agent trajectory for both Agent decision and Tool use\n",
    "\n",
    "![MLflow Trace](./static/agent/2_agent_mlflow/trace-details.png) \n",
    "\n",
    "Lets take a look at how the Agent works. At the initial stage, the LLM start reasoning and decide which tool to use, it will generate tool name and tool arguments to execute the tool \n",
    "\n",
    "![MLflow Trace](./static/agent/2_agent_mlflow/langgraph-step1.png) \n",
    "\n",
    "Then the Agent will execute the tool, you can see the tool name, arguments details and output in the orange box\n",
    "\n",
    "![MLflow Trace](./static/agent/2_agent_mlflow/langgraph-tool1.png) \n",
    "\n",
    "After tool execution, the agent will decide whether to keep choosing tools based on the current environment  \n",
    "\n",
    "![MLflow Trace](./static/agent/2_agent_mlflow/langgraph-step2.png) \n",
    "\n",
    "Then the Agent will execute the tool, since we use directly output the tool results as the final answer. The agent will stop it here\n",
    "\n",
    "![MLflow Trace](./static/agent/2_agent_mlflow/langgraph-tool2.png) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
