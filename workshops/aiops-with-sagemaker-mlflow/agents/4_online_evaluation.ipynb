{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent online Evalution with MLflow \n",
    "\n",
    "Online evaluation is a real-time assessment method for AI agents that occurs during actual deployment and interaction with users or environments. This approach provides immediate, real-world feedback on how the agent performs under genuine conditions, capturing nuances and edge cases that might not be apparent in historical data. Unlike offline evaluation, online evaluation offers insights into how the system adapts to changing user behaviors, environmental conditions, and emerging patterns in real-time.\n",
    "\n",
    "MLflow's tracking capabilities can record live metrics (such as user feedback, system behavior), allowing developers to compare actual performance against expectations and benchmark results from offline testing. The platform can also help manage model updates and versions based on real-world performance data. In this section, we will demonstration how to store online evaluation (specifically user feedback into MLflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.0\n",
      "3.0.0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "from data.data import log_data_set, log_data\n",
    "from data.solution_book import knowledge_base\n",
    "\n",
    "import sagemaker_mlflow\n",
    "import mlflow\n",
    "\n",
    "print(sagemaker_mlflow.__version__)\n",
    "print(mlflow.__version__)\n",
    "\n",
    "tracking_server_arn = \"\" \n",
    "experiment_name = \"agent-mlflow-demo\"\n",
    "mlflow.set_tracking_uri(tracking_server_arn) \n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph Agent implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/25 00:08:31 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during autologging: 2 validation errors for ChatMessage\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=[{'type': 'text', 'text':...OB0O5GjSACjI3ElqCHR8A'}], input_type=list]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "content.list[tagged-union[TextContentPart,ImageContentPart,AudioContentPart]].1\n",
      "  Input tag 'tool_use' found using 'type' does not match any of the expected tags: 'text', 'image_url', 'input_audio' [type=union_tag_invalid, input_value={'type': 'tool_use', 'nam...rOB0O5GjSACjI3ElqCHR8A'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/union_tag_invalid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Check network connectivity between client and server\n",
      "2. Verify if the server is running and accessible\n",
      "3. Increase the connection timeout settings\n",
      "4. Check for firewall rules blocking the connection\n",
      "5. Monitor network latency and bandwidth\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool \n",
    "def log_identifier(ticket_id: str) -> str:\n",
    "    \"\"\"Get error type from ticket number\n",
    "\n",
    "    Args:\n",
    "        ticket_id: ticket id\n",
    "\n",
    "    Returns:\n",
    "        an error type\n",
    "\n",
    "    \"\"\"\n",
    "    if ticket_id not in log_data_set:\n",
    "        return \"ticket id not found in the database\"\n",
    "    \n",
    "    for item in log_data:\n",
    "        if item[\"id\"] == ticket_id:\n",
    "            return item['error_name']\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def information_retriever(error_type: str) -> str:\n",
    "    \"\"\"Retriever error solution based on error type\n",
    "\n",
    "    Args:\n",
    "        error_type: user input error type\n",
    "    \n",
    "    Returns:\n",
    "        a str of steps \n",
    "    \"\"\"\n",
    "\n",
    "    if error_type not in knowledge_base.keys():\n",
    "        return \"error type not found in the knowledge base, please use your own knowledge\"\n",
    "    \n",
    "    return knowledge_base[error_type]\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model= \"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    model_provider=\"bedrock_converse\",\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an expert a resolving ETL errors. You are equiped with two tools: \n",
    "1. log_identifier: Get error type from ticket number\n",
    "2. information_retriever: Retriever error solution based on error type\n",
    "\n",
    "You will use the ticket ID to gather information about the error using the log_identifier tool. \n",
    "Then you should search the database for information on how to resolve the error using the information_retriever tool\n",
    "\n",
    "Return ONLY the numbered steps without any introduction or conclusion. Format as:\n",
    "1. step 1 text\n",
    "2. step 2 text\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools= [log_identifier, information_retriever], \n",
    "    prompt=system_prompt\n",
    ")\n",
    "\n",
    "def get_langGraph_agent_response(ticket_id = 'TICKET-001'):\n",
    "    # Prepare input for the agent\n",
    "    agent_input = {\"messages\": [{\"role\": \"user\", \"content\": ticket_id}]}\n",
    "    response = agent.invoke(agent_input)\n",
    "    return response\n",
    "\n",
    "langGraph_agent_response = get_langGraph_agent_response(ticket_id = 'TICKET-001')\n",
    "print(langGraph_agent_response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Evaluation for user feedback \n",
    "\n",
    "This example will show how you can create and store user feedback in MLflow via Tags and how you can retrieval relavent traces based on Tags \n",
    "\n",
    "> Note: For later version MLflow 3.2.0 or later installed, MLflow Feedback provides a comprehensive system for capturing quality evaluations from multiple sources - whether automated AI judges, programmatic rules, or human reviewers. This systematic approach to feedback collection enables you to understand and improve your GenAI application's performance at scale. For complete API documentation and implementation details, see the [mlflow.log_feedback()](https://mlflow.org/docs/3.4.0/api_reference/python_api/mlflow.html#mlflow.log_feedback) reference.\n",
    "\n",
    "Let's first define some methods for user feedbacks: \n",
    "- `collect_user_feedback`: this method will automatically use the latest trace, user can choose whether the trace is helpful or not. If this is helpful, then a üëç will show in UI else üëé. Users can add **ANY** key words arguments as the additional information to store in the MLflow tags\n",
    "- `collect_user_feedback_with_traceID`: this method allow you to add / edit an exiting feedback for a trace, just like `collect_user_feedback`, once you specify the trace_id, you can overwrite the values you entered before\n",
    "-  `delete_feedback`: this will delete a feedback based on your trace id and key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import AssessmentSource, AssessmentSourceType\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_user_feedback(is_helpful, user_id = 'user-dev', **kwargs):\n",
    "    '''Collect User Feedback, store them into MLflow tag\n",
    "\n",
    "    Args: \n",
    "        is_helpful: whether the output is good or not \n",
    "        user_id: user who logs the information \n",
    "        kwargs: Any key word arguments\n",
    "\n",
    "    Returns: \n",
    "        None \n",
    "    '''\n",
    "    trace_id = mlflow.get_last_active_trace_id()\n",
    "    feedback_value = 'üëç' if is_helpful else 'üëé'\n",
    "    print(f\"‚úì Feedback recorded: {feedback_value}\")\n",
    "    mlflow.set_trace_tag(trace_id=trace_id, key=\"User_ID\", value=user_id)\n",
    "    mlflow.set_trace_tag(trace_id=trace_id, key=\"User_Feedback\", value=feedback_value)\n",
    "\n",
    "    for key, value in kwargs.items():\n",
    "        mlflow.set_trace_tag(trace_id=trace_id, key= key , value=value)\n",
    "\n",
    "def collect_user_feedback_with_traceID(trace_id, is_helpful, user_id = 'user-dev', **kwargs):\n",
    "    '''Collect User Feedback using specific trace id, store them into MLflow tag\n",
    "\n",
    "    Args: \n",
    "        trace_id : trace id \n",
    "        is_helpful: whether the output is good or not \n",
    "        user_id: user who logs the information \n",
    "        kwargs: Any key word arguments\n",
    "\n",
    "    Returns: \n",
    "        None \n",
    "    '''\n",
    "\n",
    "    feedback_value = 'üëç' if is_helpful else 'üëé'\n",
    "    print(f\"‚úì Feedback recorded: {feedback_value}\")\n",
    "    mlflow.set_trace_tag(trace_id=trace_id, key=\"User_ID\", value=user_id)\n",
    "    mlflow.set_trace_tag(trace_id=trace_id, key=\"User_Feedback\", value=feedback_value)\n",
    "    #mlflow.set_trace_tag(trace_id=trace_id, key=\"WooHOO\", value=\"yeah I can store anything in str format\")\n",
    "\n",
    "    for key, value in kwargs.items():\n",
    "        mlflow.set_trace_tag(trace_id=trace_id, key= key , value=value)\n",
    "\n",
    "def delete_feedback(trace_id, key):\n",
    "    '''Delete a feedback\n",
    "\n",
    "    Args:\n",
    "        trace_id: trace id \n",
    "        key: key \n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "    mlflow.delete_trace_tag(trace_id=trace_id, key=key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Feedback recorded: üëç\n"
     ]
    }
   ],
   "source": [
    "# Get the most recent trace\n",
    "trace_id = mlflow.get_last_active_trace_id()\n",
    "\n",
    "# For example, I can have my config dictionary contains all the key-value pairs to be stored in the MLflow. \n",
    "# Let's say this is helpful and use user_id as online-demo-1 along with our key-value pairs \n",
    "\n",
    "config = {\n",
    "    'tag_anything': 'text_anything'\n",
    "}\n",
    "\n",
    "collect_user_feedback(is_helpful = True, user_id = 'online-demo-1', **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can search relavant traces based on the tags, for example, I want to search all traces with User ID equal to online-demo-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>trace</th>\n",
       "      <th>client_request_id</th>\n",
       "      <th>state</th>\n",
       "      <th>request_time</th>\n",
       "      <th>execution_duration</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>trace_metadata</th>\n",
       "      <th>tags</th>\n",
       "      <th>spans</th>\n",
       "      <th>assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cc248d650ac2410191f3027f35cf0c5b</td>\n",
       "      <td>Trace(trace_id=cc248d650ac2410191f3027f35cf0c5b)</td>\n",
       "      <td>None</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1758758909633</td>\n",
       "      <td>3866</td>\n",
       "      <td>{'messages': [{'role': 'user', 'content': 'TIC...</td>\n",
       "      <td>{'messages': [{'content': 'TICKET-001', 'addit...</td>\n",
       "      <td>{'mlflow.trace_schema.version': '3', 'mlflow.u...</td>\n",
       "      <td>{'mlflow.traceName': 'LangGraph', 'mlflow.arti...</td>\n",
       "      <td>[{'trace_id': 'z9IlPmYtYgTp/TYFoX624A==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a097eb615ed142a3832d9094dc1b9f90</td>\n",
       "      <td>Trace(trace_id=a097eb615ed142a3832d9094dc1b9f90)</td>\n",
       "      <td>None</td>\n",
       "      <td>TraceState.OK</td>\n",
       "      <td>1758550274070</td>\n",
       "      <td>3717</td>\n",
       "      <td>{'messages': [{'role': 'user', 'content': 'TIC...</td>\n",
       "      <td>{'messages': [{'content': 'TICKET-001', 'addit...</td>\n",
       "      <td>{'mlflow.trace_schema.version': '3', 'mlflow.u...</td>\n",
       "      <td>{'mlflow.traceName': 'LangGraph', 'mlflow.arti...</td>\n",
       "      <td>[{'trace_id': 'wl3fjxY6wepWhxlXeU9BuA==', 'spa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           trace_id  \\\n",
       "0  cc248d650ac2410191f3027f35cf0c5b   \n",
       "1  a097eb615ed142a3832d9094dc1b9f90   \n",
       "\n",
       "                                              trace client_request_id  \\\n",
       "0  Trace(trace_id=cc248d650ac2410191f3027f35cf0c5b)              None   \n",
       "1  Trace(trace_id=a097eb615ed142a3832d9094dc1b9f90)              None   \n",
       "\n",
       "           state   request_time  execution_duration  \\\n",
       "0  TraceState.OK  1758758909633                3866   \n",
       "1  TraceState.OK  1758550274070                3717   \n",
       "\n",
       "                                             request  \\\n",
       "0  {'messages': [{'role': 'user', 'content': 'TIC...   \n",
       "1  {'messages': [{'role': 'user', 'content': 'TIC...   \n",
       "\n",
       "                                            response  \\\n",
       "0  {'messages': [{'content': 'TICKET-001', 'addit...   \n",
       "1  {'messages': [{'content': 'TICKET-001', 'addit...   \n",
       "\n",
       "                                      trace_metadata  \\\n",
       "0  {'mlflow.trace_schema.version': '3', 'mlflow.u...   \n",
       "1  {'mlflow.trace_schema.version': '3', 'mlflow.u...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  {'mlflow.traceName': 'LangGraph', 'mlflow.arti...   \n",
       "1  {'mlflow.traceName': 'LangGraph', 'mlflow.arti...   \n",
       "\n",
       "                                               spans assessments  \n",
       "0  [{'trace_id': 'z9IlPmYtYgTp/TYFoX624A==', 'spa...          []  \n",
       "1  [{'trace_id': 'wl3fjxY6wepWhxlXeU9BuA==', 'spa...          []  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_traces = mlflow.search_traces(\n",
    "    filter_string=\"tags.User_ID = 'online-demo-1'\"\n",
    ")\n",
    "user_traces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
