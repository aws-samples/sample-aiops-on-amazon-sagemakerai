{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker managed MLflow Agent Introduction\n",
    "Welcome to the hands-on SageMaker managed MLflow workshop lab! This notebook will guide you through how to create an agent via LangGraph framework and use MLflow to log trace. We'll build an intelligent ETL error resolution Agent that can analyze error tickets and provide step-by-step solutions. Our agent will be equipped with two agent tools (log_identifer, information_retriever) to: \n",
    "1. Identify errors from ticket IDs \n",
    "2. Retrieve relevant solutions from a solution book.\n",
    "\n",
    "#### Prerequisites\n",
    "\n",
    "**Important:** You need the SageMaker Managed MLflow tracking server ARN from the workshop prerequisites section. Replace the placeholder below with your actual tracking server ARN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Intelligent IT support Agents with MLflow \n",
    "\n",
    "In this notebook lab, you will develop an IT support agent where the agent is designed for taking user IT support questions, automated ETL (Extract, Transform, Load) of the support tickets and provide actionable resolution to the user question. The support tickets are regarding issues of an IT system and the support agent helps users with ticket resolution. This intelligent agent is implemented via the LangGraph framework and instrumented with MLflow tracing, demonstrating how modern agentic architectures can elevate IT system incident response and operational reliability.\n",
    "1. Identify errors from ticket IDs \n",
    "2. Retrieve relevant solutions from a solution book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sample Architect](./static/sample-architect.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scenario Overview\n",
    "The agent is built to assist data engineers or support staff by analyzing helpdesk tickets reporting ETL pipeline errors. Upon receiving a ticket ID, it will diagnose the underlying issue and deliver targeted, step-by-step solutions—reducing downtime and improving user satisfaction.\n",
    "\n",
    "**Agent Tools**\n",
    "- `log_identifier`: Analyzes supplied ticket IDs and extracts error type, diagnostics, and metadata from pipeline logs.\n",
    "- `information_retriever`: Looks up solutions in a curated solution book and compiles actionable instructions for error resolution and mitigation.\n",
    "\n",
    "Here is the ideal resolution steps:  \n",
    "1. The user requests assistance by providing a `ticket_id`.\n",
    "2. The agent calls the `log_identifier` tool to classify the error from backend logs associated with the ticket.\n",
    "3. The agent invokes the information_retriever tool to fetch detailed solution steps based on error type and context.\n",
    "4. The user receives clear, actionable step-by-step instructions for resolving the ETL error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:33:25.566636Z",
     "iopub.status.busy": "2025-10-08T18:33:25.566350Z",
     "iopub.status.idle": "2025-10-08T18:33:33.807849Z",
     "shell.execute_reply": "2025-10-08T18:33:33.807066Z",
     "shell.execute_reply.started": "2025-10-08T18:33:25.566612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install following dependencies. Ignore any warnings\n",
    "!pip install --upgrade -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: The latest MLflow version (November, 2025 at the time of this workshop release) supported in Sagemaker managed MLflow tracking server is MLflow 3.0.0 and python 3.9 or later, You can find more information [here](https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html).\n",
    "> To make sure you can successfuly run this notebook you will need use the compatible version, i.e. install `sagemaker_mlflow==0.1.0` and `mlflow=3.0.0`. This is already provided as part of the `requirements.txt` installation. The Sagemaker managed MLflow tracking server can be different than the mlflow SDK python version used as long as the APIs used in the Sagemaker managed MLflow tracking server MLflow versions are supported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:24.539512Z",
     "iopub.status.busy": "2025-10-08T18:38:24.539051Z",
     "iopub.status.idle": "2025-10-08T18:38:24.547045Z",
     "shell.execute_reply": "2025-10-08T18:38:24.546320Z",
     "shell.execute_reply.started": "2025-10-08T18:38:24.539487Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "## Import Data \n",
    "from data.data import log_data_set, log_data\n",
    "from data.solution_book import solution_book\n",
    "\n",
    "## Import MLflow Libs\n",
    "import sagemaker_mlflow \n",
    "import mlflow\n",
    "\n",
    "## Check AWS Credentials \n",
    "try:\n",
    "    boto3.client('bedrock-runtime')\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring AWS credentials: {e}\")\n",
    "    print(\"Please set your AWS credentials before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's examine our sample synthesis data that represents a typical support ticket system. `log_data` is a list of dictionaries contains ticked id and error name, for this workshop, we will use a simplified version to extract the error_name based on the ticket_id. `solution_book` is a dictionary where the key is the error name, the value is solution steps. Here we use the dictionary to mimic the real world use case solution which normally use Vector Store Knowledge Base to retrieve relevant solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:28.264476Z",
     "iopub.status.busy": "2025-10-08T18:38:28.264189Z",
     "iopub.status.idle": "2025-10-08T18:38:28.270767Z",
     "shell.execute_reply": "2025-10-08T18:38:28.269995Z",
     "shell.execute_reply.started": "2025-10-08T18:38:28.264455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'TICKET-001', 'error_name': 'Connection Timeout'},\n",
       " {'id': 'TICKET-002', 'error_name': 'Database Authentication Failed'},\n",
       " {'id': 'TICKET-003', 'error_name': 'Memory Overflow'},\n",
       " {'id': 'TICKET-004', 'error_name': 'API Rate Limit Exceeded'},\n",
       " {'id': 'TICKET-005', 'error_name': 'Invalid SSL Certificate'},\n",
       " {'id': 'TICKET-006', 'error_name': 'Disk Space Full'},\n",
       " {'id': 'TICKET-007', 'error_name': 'Network Connectivity Lost'},\n",
       " {'id': 'TICKET-008', 'error_name': 'Permission Denied'},\n",
       " {'id': 'TICKET-009', 'error_name': 'Service Unavailable'},\n",
       " {'id': 'TICKET-010', 'error_name': 'Configuration File Missing'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:28.659643Z",
     "iopub.status.busy": "2025-10-08T18:38:28.659373Z",
     "iopub.status.idle": "2025-10-08T18:38:28.664094Z",
     "shell.execute_reply": "2025-10-08T18:38:28.663325Z",
     "shell.execute_reply.started": "2025-10-08T18:38:28.659622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Connection Timeout': '1. Check network connectivity between client and server\\n2. Verify if the server is running and accessible\\n3. Increase the connection timeout settings\\n4. Check for firewall rules blocking the connection\\n5. Monitor network latency and bandwidth\\n    ',\n",
       " 'Database Authentication Failed': '1. Verify database credentials are correct\\n2. Check if the database user account is locked\\n3. Ensure database service is running\\n4. Review database access permissions\\n5. Check for recent password changes\\n    ',\n",
       " 'Memory Overflow': '1. Analyze application memory usage patterns\\n2. Increase available memory or swap space\\n3. Look for memory leaks in the application\\n4. Optimize database queries and caching\\n5. Consider implementing memory pooling\\n    ',\n",
       " 'Invalid SSL Certificate': '1. Check certificate expiration date\\n2. Verify certificate chain is complete\\n3. Ensure certificate matches domain name\\n4. Update SSL certificate if expired\\n5. Check certificate authority validity\\n    ',\n",
       " 'Disk Space Full': '1. Remove temporary and unnecessary files\\n2. Implement log rotation\\n3. Archive old data\\n4. Expand disk space\\n5. Monitor disk usage trends\\n    ',\n",
       " 'Network Connectivity Lost': '1. Check physical network connections\\n2. Verify router and switch status\\n3. Test DNS resolution\\n4. Check for network interface errors\\n5. Monitor network traffic patterns\\n    ',\n",
       " 'Permission Denied': '1. Review user access rights\\n2. Check file and directory permissions\\n3. Verify group memberships\\n4. Update security policies\\n5. Audit access control lists\\n    ',\n",
       " 'Service Unavailable': '1. Check service status and logs\\n2. Restart the service\\n3. Verify dependencies are running\\n4. Check system source documents. Monitor service health metrics\\n    ',\n",
       " 'Configuration File Missing': '1. Locate backup configuration files\\n2. Restore from version control\\n3. Create new configuration file with default settings\\n4. Check file path and permissions\\n5. Verify application deployment process\\n    '}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SagemakerAI MLFlow\n",
    "We will configure MLflow integration with Amazon SageMaker for tracking and tracing agent-based workflows. Frist we establishes a connection to a specific SageMakerAI MLflow Tracking Server using an ARN (Amazon Resource Name). \n",
    "The `mlflow.set_tracking_uri()` method directs all subsequent MLflow logging operations to this server, ensuring experiment metadata is stored in the secure backend maintained by SageMaker.\n",
    "\n",
    "You can organize all your MLFlow observibility data by setting `mlflow.set_experiment(\"<YOUR_MLFLOW_EXPERIMENT_NAME>\")`. Using which MLflow allows you to group runs under experiments, which can be useful for comparing runs intended to tackle a particular task.\n",
    "\n",
    "We will retrieve the stored notebook values containing the SageMakerAI MLflow Tracking Server ARN. If the stored value is empty you can enter your tracking server arn to the following place holder string `TRACKING_SERVER_ARN`. Additionally, you can give any MLflow experiment name, in this workshop, we will give an experiment name: agent-mlflow-demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:29.166987Z",
     "iopub.status.busy": "2025-10-08T18:38:29.166717Z",
     "iopub.status.idle": "2025-10-08T18:38:29.173246Z",
     "shell.execute_reply": "2025-10-08T18:38:29.172352Z",
     "shell.execute_reply.started": "2025-10-08T18:38:29.166967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "TRACKING_SERVER_ARN             -> 'arn:aws:sagemaker:us-east-2:198346569064:mlflow-t\n"
     ]
    }
   ],
   "source": [
    "%store -r \n",
    "\n",
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:29.365612Z",
     "iopub.status.busy": "2025-10-08T18:38:29.365352Z",
     "iopub.status.idle": "2025-10-08T18:38:29.370102Z",
     "shell.execute_reply": "2025-10-08T18:38:29.369305Z",
     "shell.execute_reply.started": "2025-10-08T18:38:29.365592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:sagemaker:us-east-2:198346569064:mlflow-tracking-server/mlflow-labs'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRACKING_SERVER_ARN\n",
    "# If the stored value is empty set your SageMaker Managed MLflow tracking server ARN from prerequisites\n",
    "#TRACKING_SERVER_ARN = \"ENTER YOUR MLFLOW TRACKIHG SERVER ARN HERE\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:29.779166Z",
     "iopub.status.busy": "2025-10-08T18:38:29.778898Z",
     "iopub.status.idle": "2025-10-08T18:38:30.002138Z",
     "shell.execute_reply": "2025-10-08T18:38:30.001568Z",
     "shell.execute_reply.started": "2025-10-08T18:38:29.779147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://agent-mlflow-ws/1', creation_time=1759512154722, experiment_id='1', last_update_time=1759512154722, lifecycle_stage='active', name='agent-mlflow-demo', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_server_arn = TRACKING_SERVER_ARN \n",
    "experiment_name = \"agent-mlflow-demo\"\n",
    "\n",
    "# Set MLflow SDK to your configured tracking server \n",
    "mlflow.set_tracking_uri(tracking_server_arn) \n",
    "# Create or select an MLflow experiment\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will use LangGraph agent, let's set up the auto tracing for LangGraph. \n",
    "\n",
    "> `mlflow.langchain.autolog()` is a function within the MLflow LangChain flavor that enables automatic logging of crucial details about LangChain models and their execution. This feature simplifies experiment tracking and analysis by eliminating the need for explicit logging statements. By default, `mlflow.langchain.autolog()`automatically logs traces of your LangChain components, providing a visual representation of data flow through chains, agents, and retrievers. This includes invocations of methods like invoke, batch, stream, ainvoke, abatch, astream, get_relevant_documents (for retrievers), and `__call__` (for Chains and AgentExecutors).\n",
    "\n",
    "> Note: You can use the the generic high-level autologging function mlflow.autolog() to capture the traces, however, when mlflow.autolog() called, it attempts to enable autologging for all supported standard ML libraries you have installed including the agentic libraries which can make it difficuilt to debug agentic behaviour and deviates the primary focus of helping with agentic framework tracing. Where you use the agentic framework specific autolog like mlflow.langchain.autolog(), Traces (detailed execution flow) are the primary log item with scope specific to focuse only on the agentic framework integration like LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:31.963211Z",
     "iopub.status.busy": "2025-10-08T18:38:31.962912Z",
     "iopub.status.idle": "2025-10-08T18:38:31.966974Z",
     "shell.execute_reply": "2025-10-08T18:38:31.966115Z",
     "shell.execute_reply.started": "2025-10-08T18:38:31.963187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.0\n"
     ]
    }
   ],
   "source": [
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:32.138119Z",
     "iopub.status.busy": "2025-10-08T18:38:32.137847Z",
     "iopub.status.idle": "2025-10-08T18:38:32.683629Z",
     "shell.execute_reply": "2025-10-08T18:38:32.682954Z",
     "shell.execute_reply.started": "2025-10-08T18:38:32.138097Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize sample data for the agent tool \n",
    "To build a practical ETL error resolution agent, we first need to provide sample lookup data for each tool operation. In this demonstration:\n",
    "- `log_data` mimics a support ticket backend, mapping ticket IDs to error types.\n",
    "- `solution_book` acts as a simple knowledge base, mapping error names to resolution steps.\n",
    "\n",
    "In production, these would typically be external databases, knowledge stores, or APIs. Here, we simplify with in-notebook Python objects for demonstration clarity.\n",
    "\n",
    "> Note: This sample data demonstrates a typical support ticket system. `log_data` is a list of dictionaries contains ticked id and error name, for this workshop lab, we will use a simplified version to extract the error_name based on the ticket_id. `solution_book` is a python dictionary where the key is the error name, the value is resolution steps. Here we use the dictionary to mimic the real world use case solution which normally use data store like a database or a Vector Store Knowledge Base to retrieve relevant solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:32.684606Z",
     "iopub.status.busy": "2025-10-08T18:38:32.684399Z",
     "iopub.status.idle": "2025-10-08T18:38:32.691664Z",
     "shell.execute_reply": "2025-10-08T18:38:32.690972Z",
     "shell.execute_reply.started": "2025-10-08T18:38:32.684587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'TICKET-001', 'error_name': 'Connection Timeout'},\n",
       " {'id': 'TICKET-002', 'error_name': 'Database Authentication Failed'},\n",
       " {'id': 'TICKET-003', 'error_name': 'Memory Overflow'},\n",
       " {'id': 'TICKET-004', 'error_name': 'API Rate Limit Exceeded'},\n",
       " {'id': 'TICKET-005', 'error_name': 'Invalid SSL Certificate'},\n",
       " {'id': 'TICKET-006', 'error_name': 'Disk Space Full'},\n",
       " {'id': 'TICKET-007', 'error_name': 'Network Connectivity Lost'},\n",
       " {'id': 'TICKET-008', 'error_name': 'Permission Denied'},\n",
       " {'id': 'TICKET-009', 'error_name': 'Service Unavailable'},\n",
       " {'id': 'TICKET-010', 'error_name': 'Configuration File Missing'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize sample log data\n",
    "# Each entry in log_data is a ticket with a unique ID and its error type\n",
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:33.094522Z",
     "iopub.status.busy": "2025-10-08T18:38:33.094255Z",
     "iopub.status.idle": "2025-10-08T18:38:33.098359Z",
     "shell.execute_reply": "2025-10-08T18:38:33.097785Z",
     "shell.execute_reply.started": "2025-10-08T18:38:33.094503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Connection Timeout': '1. Check network connectivity between client and server\\n2. Verify if the server is running and accessible\\n3. Increase the connection timeout settings\\n4. Check for firewall rules blocking the connection\\n5. Monitor network latency and bandwidth\\n    ',\n",
       " 'Database Authentication Failed': '1. Verify database credentials are correct\\n2. Check if the database user account is locked\\n3. Ensure database service is running\\n4. Review database access permissions\\n5. Check for recent password changes\\n    ',\n",
       " 'Memory Overflow': '1. Analyze application memory usage patterns\\n2. Increase available memory or swap space\\n3. Look for memory leaks in the application\\n4. Optimize database queries and caching\\n5. Consider implementing memory pooling\\n    ',\n",
       " 'Invalid SSL Certificate': '1. Check certificate expiration date\\n2. Verify certificate chain is complete\\n3. Ensure certificate matches domain name\\n4. Update SSL certificate if expired\\n5. Check certificate authority validity\\n    ',\n",
       " 'Disk Space Full': '1. Remove temporary and unnecessary files\\n2. Implement log rotation\\n3. Archive old data\\n4. Expand disk space\\n5. Monitor disk usage trends\\n    ',\n",
       " 'Network Connectivity Lost': '1. Check physical network connections\\n2. Verify router and switch status\\n3. Test DNS resolution\\n4. Check for network interface errors\\n5. Monitor network traffic patterns\\n    ',\n",
       " 'Permission Denied': '1. Review user access rights\\n2. Check file and directory permissions\\n3. Verify group memberships\\n4. Update security policies\\n5. Audit access control lists\\n    ',\n",
       " 'Service Unavailable': '1. Check service status and logs\\n2. Restart the service\\n3. Verify dependencies are running\\n4. Check system source documents. Monitor service health metrics\\n    ',\n",
       " 'Configuration File Missing': '1. Locate backup configuration files\\n2. Restore from version control\\n3. Create new configuration file with default settings\\n4. Check file path and permissions\\n5. Verify application deployment process\\n    '}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize sample solution book\n",
    "# Each error type maps to a list of step-by-step instructions for resolution\n",
    "solution_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These staged dictionaries form the dynamic data foundation for the agent tools you’ll implement and invoke within your LangGraph workflow:\n",
    "- The log_identifier tool will look up a ticket ID in log_data to extract the relevant error type.\n",
    "- The information_retriever tool will fetch detailed, actionable remediation steps from the solution_book, given that error type.\n",
    "\n",
    "> In a real-world scenario, these would likely be microservices, API calls, or vector search queries to production data stores. For this workshop, the simple data structures let you focus on agent logic, tool call orchestration, and MLflow-powered trace monitoring.\n",
    "\n",
    "You’re now ready to define, register, and test your agent tools in the LangGraph agent framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Agent Tools in LangGraph\n",
    "In LangGraph, agent tools let your LLM-powered agent interact with the world beyond language—retrieving information, performing searches, or calling APIs. Tools are simply Python functions, but with the @tool decorator they become part of the agent’s action space: the agent can decide when and how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Lets import libaries from LangGraph Framework. here: \n",
    "1. `create_react_agent`: Create an agent that uses ReAct prompting.\n",
    "2. `init_chat_model`: Initialize a ChatModel in a single line using the model’s name and provider.\n",
    "3. `langchain_core.tools`: Tool that takes in function or coroutine directly. You can customize your tool with `@tool` decoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:34.613326Z",
     "iopub.status.busy": "2025-10-08T18:38:34.613023Z",
     "iopub.status.idle": "2025-10-08T18:38:39.462452Z",
     "shell.execute_reply": "2025-10-08T18:38:39.461797Z",
     "shell.execute_reply.started": "2025-10-08T18:38:34.613304Z"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The log_identifier Tool\n",
    "This function allows the agent to look up the error type associated with a given support ticket ID. This is your agent’s primary hook into your simulated support system.\n",
    "- The @tool decorator registers this as an agent-available tool. The @tool decorator is core: it annotates a function so that your agent can see (and use) it as part of its available toolkit.\n",
    "- The agent will call this function when it needs to map a ticket ID to a specific error type.\n",
    "- A clear docstring is critical: the LLM references these descriptions to decide when the tool is appropriate to use.\n",
    "- The function loops through log_data to find the corresponding error, allowing easy simulation and interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:39.463895Z",
     "iopub.status.busy": "2025-10-08T18:38:39.463307Z",
     "iopub.status.idle": "2025-10-08T18:38:39.470584Z",
     "shell.execute_reply": "2025-10-08T18:38:39.469964Z",
     "shell.execute_reply.started": "2025-10-08T18:38:39.463872Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool \n",
    "def log_identifier(ticket_id: str) -> str:\n",
    "    \"\"\"Get error type from ticket number\n",
    "\n",
    "    Args:\n",
    "        ticket_id: ticket id\n",
    "\n",
    "    Returns:\n",
    "        an error type\n",
    "\n",
    "    \"\"\"\n",
    "    if ticket_id not in log_data_set:\n",
    "        return \"ticket id not found in the database\"\n",
    "    \n",
    "    for item in log_data:\n",
    "        if item[\"id\"] == ticket_id:\n",
    "            return item['error_name']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The information_retriever Tool\n",
    "After an error type is found, the agent can fetch the appropriate, step-by-step solution using this retrieval tool:\n",
    "- The @tool(return_direct=True) tells LangGraph to return this tool’s output to the user directly—useful for final answers (e.g., resolution steps).\n",
    "- Like before, the docstring describes the tool’s intent and usage.\n",
    "- This tool looks up solution steps as a string, making it perfect for the agent to hand off clear resolution instructions directly to the end-user.\n",
    "- If the error type isn't found, it provides a safe fallback message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:39.471723Z",
     "iopub.status.busy": "2025-10-08T18:38:39.471410Z",
     "iopub.status.idle": "2025-10-08T18:38:39.477868Z",
     "shell.execute_reply": "2025-10-08T18:38:39.477140Z",
     "shell.execute_reply.started": "2025-10-08T18:38:39.471703Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool(return_direct=True)\n",
    "def information_retriever(error_type: str) -> str:\n",
    "    \"\"\"Retriever error solution based on error type\n",
    "\n",
    "    Args:\n",
    "        error_type: user input error type\n",
    "    \n",
    "    Returns:\n",
    "        a str of steps \n",
    "    \"\"\"\n",
    "\n",
    "    if error_type not in solution_book.keys():\n",
    "        return \"error type not found in the knowledge base, please use your own knowledge\"\n",
    "    \n",
    "    return solution_book[error_type]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agent Workflow:\n",
    "- Agent receives a user input (e.g., help request with ticket id)\n",
    "- Calls log_identifier to transform the ticket id to an error type\n",
    "- Uses information_retriever to fetch actionable guidance for the error\n",
    "- Returns steps directly to the user (since return_direct=True)\n",
    "\n",
    "You can now proceed to wire these tools into your LangGraph agent with create_react_agent. Each tool call will be traced in MLflow for transparency and assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Language Model with AWS Bedrock Claude 3.5 Haiku\n",
    "We use the init_chat_model function to create a consistent interface for initializing various LLM providers. In this workshop, we'll use Claude 3.5 Haiku hosted on AWS Bedrock as our LLM to power the agent's reasoning and decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:39.480034Z",
     "iopub.status.busy": "2025-10-08T18:38:39.479812Z",
     "iopub.status.idle": "2025-10-08T18:38:39.668226Z",
     "shell.execute_reply": "2025-10-08T18:38:39.667559Z",
     "shell.execute_reply.started": "2025-10-08T18:38:39.480016Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = init_chat_model(\n",
    "    model= \"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    model_provider=\"bedrock_converse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model: Specifies the exact model identifier for Claude 3.5 Haiku on Bedrock.\n",
    "- model_provider: Indicates the provider service, here bedrock_converse.\n",
    "\n",
    "This LLM instance will be the brain of the agent, generating responses, deciding tool invocations, and following the reasoning workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the System Prompt for Agent Behavior\n",
    "The system prompt acts as the agent’s personality and instruction manual. We define it clearly to instruct the agent that it is an expert in resolving ETL errors, equipped with two tools, and specify the expected workflow and output formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system prompt acts as the agent’s personality and instruction manual. We define it clearly to instruct the agent that it is an expert in resolving ETL errors, equipped with two tools, and specify the expected workflow and output formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:39.669428Z",
     "iopub.status.busy": "2025-10-08T18:38:39.669126Z",
     "iopub.status.idle": "2025-10-08T18:38:39.672973Z",
     "shell.execute_reply": "2025-10-08T18:38:39.672116Z",
     "shell.execute_reply.started": "2025-10-08T18:38:39.669400Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert a resolving ETL errors. You are equiped with two tools: \n",
    "1. log_identifier: Get error type from ticket number\n",
    "2. information_retriever: Retriever error solution based on error type\n",
    "\n",
    "You will use the ticket ID to gather information about the error using the log_identifier tool. \n",
    "Then you should search the database for information on how to resolve the error using the information_retriever tool\n",
    "\n",
    "Return ONLY the numbered steps without any introduction or conclusion. Format as:\n",
    "1. step 1 text\n",
    "2. step 2 text\n",
    "...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This prompt ensures the agent uses the right tools in sequence.\n",
    "- It emphasizes output format consistency, making it easier for end users to follow.\n",
    "- Provides context to the LLM for optimized, goal-directed behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next utilize the create_react_agent function, which builds a ReAct agent: a Reasoning and Acting agent that can iteratively decide which tool to call and what responses to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:39.674524Z",
     "iopub.status.busy": "2025-10-08T18:38:39.674230Z",
     "iopub.status.idle": "2025-10-08T18:38:39.689594Z",
     "shell.execute_reply": "2025-10-08T18:38:39.688909Z",
     "shell.execute_reply.started": "2025-10-08T18:38:39.674496Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools= [log_identifier, information_retriever], \n",
    "    prompt=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model: The LLM instance driving the agent.\n",
    "- tools: List of pre-defined tools (functions marked with @tool) the agent can call during reasoning.\n",
    "- prompt: The system prompt that sets agent instructions and behavior.\n",
    "\n",
    "`create_react_agent` abstracts away the complexity of integrating multiple tools and manages the reasoning cycle per the ReAct paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:39.690688Z",
     "iopub.status.busy": "2025-10-08T18:38:39.690393Z",
     "iopub.status.idle": "2025-10-08T18:38:39.694109Z",
     "shell.execute_reply": "2025-10-08T18:38:39.693275Z",
     "shell.execute_reply.started": "2025-10-08T18:38:39.690660Z"
    }
   },
   "outputs": [],
   "source": [
    "# (Optional) Draw agent graph to local file \n",
    "# agent.get_graph(xray=True).draw_mermaid_png(\n",
    "#     output_file_path=\"graph_diagram.png\",  # Specify where to save the PNG image\n",
    "#     background_color=\"white\", \n",
    "#     padding=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a clean interface for interacting with our agent. It formats the input as a message (following the chat format), invokes the agent, and extracts the final response content. The agent will automatically use the tools in the correct sequence to resolve the ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:39.695882Z",
     "iopub.status.busy": "2025-10-08T18:38:39.695665Z",
     "iopub.status.idle": "2025-10-08T18:38:39.699803Z",
     "shell.execute_reply": "2025-10-08T18:38:39.699102Z",
     "shell.execute_reply.started": "2025-10-08T18:38:39.695864Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_langGraph_agent_response(user_prompt):\n",
    "    # Prepare input for the agent\n",
    "    agent_input = {\"messages\": [{\"role\": \"user\", \"content\": user_prompt}]}\n",
    "    response = agent.invoke(agent_input)\n",
    "    return response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we test our agent with a sample user prompt including the ticket ID. The agent should:\n",
    "\n",
    "1. Use the log_identifier tool to find that TICKET-001 corresponds to \"Connection Timeout\"\n",
    "2. Use the information_retriever tool to get the solution steps\n",
    "3. Return the formatted solution steps to the user\n",
    "\n",
    "When you run the next code cell, you will see the agent reponse to the user prompt with a numbered list of steps for resolving the ticket issue, demonstrating that your agent successfully chained the tools together to provide a complete solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:40.253641Z",
     "iopub.status.busy": "2025-10-08T18:38:40.253363Z",
     "iopub.status.idle": "2025-10-08T18:38:45.725452Z",
     "shell.execute_reply": "2025-10-08T18:38:45.724625Z",
     "shell.execute_reply.started": "2025-10-08T18:38:40.253622Z"
    }
   },
   "outputs": [],
   "source": [
    "langGraph_agent_response = get_langGraph_agent_response(user_prompt = 'Can you help me with this ticket_id : TICKET-001?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-08T18:38:45.726533Z",
     "iopub.status.busy": "2025-10-08T18:38:45.726308Z",
     "iopub.status.idle": "2025-10-08T18:38:45.731612Z",
     "shell.execute_reply": "2025-10-08T18:38:45.731007Z",
     "shell.execute_reply.started": "2025-10-08T18:38:45.726514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Check network connectivity between client and server\n",
      "2. Verify if the server is running and accessible\n",
      "3. Increase the connection timeout settings\n",
      "4. Check for firewall rules blocking the connection\n",
      "5. Monitor network latency and bandwidth\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(langGraph_agent_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will be able to see the tracing in the MLflow. \n",
    "\n",
    "1. Open your SageMaker managed MLflow UI\n",
    "2. In the MLflow UI navigate to the `Traces` tab to see traces of the agent’s reasoning steps and tool calls, enabling rich observability for debugging and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
